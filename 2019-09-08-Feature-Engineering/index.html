<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 5.1.1"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.ico"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.ico"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css"><link rel="stylesheet" href="https://cdn.bootcdn.net/ajax/libs/pace/1.0.2/themes/silver/pace-theme-center-atom.min.css"><script src="//cdn.bootcdn.net/ajax/libs/pace/1.0.2/pace.min.js"></script><script id="hexo-configurations">var NexT=window.NexT||{},CONFIG={hostname:"blog.harumonia.moe",root:"/",scheme:"Gemini",version:"7.8.0",exturl:!1,sidebar:{position:"left",display:"post",padding:18,offset:12,onmobile:!1},copycode:{enable:!0,show_result:!0,style:"mac"},back2top:{enable:!0,sidebar:!0,scrollpercent:!0},bookmark:{enable:!1,color:"#222",save:"auto"},fancybox:!1,mediumzoom:!0,lazyload:!0,pangu:!1,comments:{style:"tabs",active:null,storage:!0,lazyload:!1,nav:null},algolia:{hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}},localsearch:{enable:!0,trigger:"auto",top_n_per_article:1,unescape:!1,preload:!1},motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},path:"search.xml"}</script><meta name="description" content="至此,看过了很多的机器学习的文章,发现大多是重于算法的讲解,但是机器学习是 对数据集进行算法处理 ,数据集的重要地位不言而喻.个人认为,优质的数据集可以极大地提高模型精度和运算效率.一个很好的例子就是 sklearn 的 dataset,处理起来顺滑无比,但是在对上一篇文章所讲的泰坦尼克数据集进行机器学习时,如果也像在鸢尾花集上那样,结果自然是惨不忍睹.所以这里单开一篇讲一下特征工程. 参考资料:"><meta property="og:type" content="article"><meta property="og:title" content="浅谈特征工程 Feature  Engineering"><meta property="og:url" content="https://blog.harumonia.moe/2019-09-08-Feature-Engineering/index.html"><meta property="og:site_name" content="Zaxon"><meta property="og:description" content="至此,看过了很多的机器学习的文章,发现大多是重于算法的讲解,但是机器学习是 对数据集进行算法处理 ,数据集的重要地位不言而喻.个人认为,优质的数据集可以极大地提高模型精度和运算效率.一个很好的例子就是 sklearn 的 dataset,处理起来顺滑无比,但是在对上一篇文章所讲的泰坦尼克数据集进行机器学习时,如果也像在鸢尾花集上那样,结果自然是惨不忍睹.所以这里单开一篇讲一下特征工程. 参考资料:"><meta property="og:locale" content="zh_CN"><meta property="article:published_time" content="2019-09-08T16:05:25.000Z"><meta property="article:modified_time" content="2019-09-08T16:05:25.000Z"><meta property="article:author" content="harumonia"><meta property="article:tag" content="特征工程"><meta name="twitter:card" content="summary"><link rel="canonical" href="https://blog.harumonia.moe/2019-09-08-Feature-Engineering/"><script id="page-configurations">CONFIG.page={sidebar:"",isHome:!1,isPost:!0,lang:"zh-CN"}</script><title>浅谈特征工程 Feature Engineering | Zaxon</title><noscript><style>.sidebar-inner,.use-motion .brand,.use-motion .collection-header,.use-motion .comments,.use-motion .menu-item,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line-before i{left:initial}.use-motion .logo-line-after i{right:initial}</style></noscript><script>fetch("http://39.108.229.166:5002/get-short-cn-poetry").then(function(t){return t.json()}).then(function(t){var n=document.getElementById("hitokoto"),e=document.getElementById("hitofrom");n.innerHTML=t.msg,e.innerHTML="--- "+t.from}).catch(function(t){console.error(t)})</script></head><body itemscope itemtype="http://schema.org/WebPage"><div class="container use-motion"><div class="headband"></div><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏"><span class="toggle-line toggle-line-first"></span> <span class="toggle-line toggle-line-middle"></span> <span class="toggle-line toggle-line-last"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span><h1 class="site-title">Zaxon</h1><span class="logo-line-after"><i></i></span></a><p class="site-subtitle" itemprop="description">Find the key of soul</p><p class="site-hit" id="hitokoto"></p><p class="site-hit" id="hitofrom"></p></div><div class="site-nav-right"><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-fw fa-fab fa-home"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-fw fa-fab fa-user"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-fw fa-fab fa-tags"></i>标签<span class="badge">54</span></a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-fw fa-fab fa-th"></i>分类<span class="badge">16</span></a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-fw fa-fab fa-archive"></i>归档<span class="badge">102</span></a></li><li class="menu-item menu-item-book"><a href="/books/" rel="section"><i class="fa fa-fw fa-fab fa-book"></i>图书</a></li><li class="menu-item menu-item-movie"><a href="/movies/" rel="section"><i class="fa fa-fw fa-fab fa-film"></i>电影</a></li><li class="menu-item menu-item-game"><a href="/games/" rel="section"><i class="fa fa-fw fa-fab fa-gamepad"></i>游戏</a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索</a></li></ul></nav><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"><input autocomplete="off" autocapitalize="off" placeholder="搜索..." spellcheck="false" type="search" class="search-input"></div><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span></div><div id="search-result"><div id="no-result"><i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i></div></div></div></div></div></header><div class="reading-progress-bar"></div><a href="https://github.com/zxjlm" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><main class="main"><div class="main-inner"><div class="content-wrap"><div class="content post posts-expand"><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://blog.harumonia.moe/2019-09-08-Feature-Engineering/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="https://harumona-blog.oss-cn-beijing.aliyuncs.com/blog/Ocabe.webp"><meta itemprop="name" content="harumonia"><meta itemprop="description" content="lazy"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Zaxon"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">浅谈特征工程 Feature Engineering</h1><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2019-09-08 16:05:25" itemprop="dateCreated datePublished" datetime="2019-09-08T16:05:25+00:00">2019-09-08</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-folder-o"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%E6%BA%90%E6%B5%81%E6%B8%85%E6%B3%89/" itemprop="url" rel="index"><span itemprop="name">源流清泉</span></a> </span></span><span id="/2019-09-08-Feature-Engineering/" class="post-meta-item leancloud_visitors" data-flag-title="浅谈特征工程 Feature  Engineering" title="阅读次数"><span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="post-meta-item-text">阅读次数：</span> <span class="leancloud-visitors-count"></span> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-comment-o"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/2019-09-08-Feature-Engineering/#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/2019-09-08-Feature-Engineering/" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="fa fa-file-word-o"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>3.4k</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="fa fa-clock-o"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>11 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><p>至此,看过了很多的机器学习的文章,发现大多是重于算法的讲解,但是机器学习是 <em>对数据集进行算法处理</em> ,数据集的重要地位不言而喻.<br>个人认为,优质的数据集可以极大地提高模型精度和运算效率.一个很好的例子就是 sklearn 的 dataset,处理起来顺滑无比,但是在对上一篇文章所讲的泰坦尼克数据集进行机器学习时,如果也像在鸢尾花集上那样,结果自然是惨不忍睹.<br>所以这里单开一篇讲一下特征工程.</p><p>参考资料:<br>kaggle-sina\Anisotropic<br>$Feature\ Engineering$<br>Tsai</p><p>ps.<br>基础的一些处理可以直接使用 numpy+pandas,灵活小巧.<br>不过如果涉及到一些统计方法,那么建议使用 sklearn 封装好的类.</p><h1 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h1><h2 id="无量纲化"><a href="#无量纲化" class="headerlink" title="无量纲化"></a>无量纲化</h2><p>在机器学习算法实践中，我们往往有着将不同规格的数据转换到同一规格，或不同分布的数据转换到某个特定分布 的需求，这种需求统称为将数据“无量纲化”。譬如梯度和矩阵为核心的算法中，譬如逻辑回归，支持向量机，神经 网络，无量纲化可以加快求解速度.</p><p>数据的无量纲化可以是线性的，也可以是非线性的。<br>线性的无量纲化包括中心化(Zero-centered 或者 Mean- subtraction)处理和缩放处理(Scale)。</p><h3 id="数据归一化"><a href="#数据归一化" class="headerlink" title="数据归一化"></a>数据归一化</h3><p>当数据(x)按照最小值中心化后，再按极差(最大值 - 最小值)缩放，数据移动了最小值个单位，并且会被收敛到[0,1]之间，而这个过程，就叫做数据归一化(Normalization，又称 Min-Max Scaling)。 <em>归一化之后的数据服从正态分布.</em></p><blockquote><p>MinMaxScaler 在不涉及距离度量、梯度、协方差计算以及数据需要被压缩到特定区间时使用广泛，比如数字图像<br>处理中量化像素强度时，都会使用 MinMaxScaler 将数据压缩于[0,1]区间之中。</p></blockquote><p>ps.使用 numpy 也可以快速实现归一化,不过在对大量数据进行处理时效率不及 sklearn</p><h3 id="数据标准化"><a href="#数据标准化" class="headerlink" title="数据标准化"></a>数据标准化</h3><p>当数据(x)按均值(μ)中心化后，再按标准差(σ)缩放，数据就会服从为均值为 0，方差为 1 的正态分布(即标准正态分 布)，而这个过程，就叫做数据标准化(Standardization，又称 Z-score normalization).</p><h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>大多数机器学习算法中，会选择 StandardScaler 来进行特征缩放，因为 MinMaxScaler 对异常值非常敏<br>感。在 PCA，聚类，逻辑回归，支持向量机，神经网络这些算法中，StandardScaler 往往是最好的选择。</p><h2 id="缺失值-SimpleImputer"><a href="#缺失值-SimpleImputer" class="headerlink" title="缺失值 SimpleImputer"></a>缺失值 SimpleImputer</h2><p>在 <strong>使用随机森林解决”泰坦尼克幸存”问题(1)</strong> 一文中,我使用了 replace 来进行缺失值的填补,不过 sklearn 中内置了 SimpleImputer 来完成这项工作.</p><h2 id="编码与哑变量"><a href="#编码与哑变量" class="headerlink" title="编码与哑变量"></a>编码与哑变量</h2><p>为了让数据适应算法和库，我们必须将数据进行编码，即是说，将文字型数据转换为数值型。</p><h3 id="编码"><a href="#编码" class="headerlink" title="编码"></a>编码</h3><ul><li>LabelEncoder:标签专用，能够将分类转换为分类数值</li><li>OrdinalEncoder:特征专用，能够将分类特征转换为分类数值</li></ul><h3 id="哑变量"><a href="#哑变量" class="headerlink" title="哑变量"></a>哑变量</h3><p>把分类转换成数字的时候，忽略了数字中自带的数学性质，所以给算法传达了一些不准确的信息，而这会影响我们的建模。<br>OrdinalEncoder 可以用来处理有序变量，但对于名义变量，我们只有使用哑变量的方式来处理，才能够尽量向算法传达最准确的信息</p><h2 id="二值化与分段"><a href="#二值化与分段" class="headerlink" title="二值化与分段"></a>二值化与分段</h2><p>用来处理连续型特征.</p><h3 id="二值化"><a href="#二值化" class="headerlink" title="二值化"></a>二值化</h3><p>根据阈值将数据二值化(将特征值设置为 0 或 1)，用于处理连续型变量。大于阈值的值映射为 1，而小于或等于阈值的值映射为 0.</p><h3 id="分段"><a href="#分段" class="headerlink" title="分段"></a>分段</h3><p>将连续型变量划分为分类变量,也就是常说的分箱.</p><p><strong>注意分箱的编码方式和定义箱宽的方式</strong></p><h1 id="特征选择-feature-selection"><a href="#特征选择-feature-selection" class="headerlink" title="特征选择 feature_selection"></a>特征选择 feature_selection</h1><table><thead><tr><th>特征提取(feature extraction)</th><th>特征创造(feature creation)</th><th>特征选择(feature selection)</th></tr></thead><tbody><tr><td>从文字，图像，声音等其他非结构化数据中提取新信息作为特征。比如说，从淘宝宝贝的名称中提取出产品类别，产品颜色，是否是网红产品等等。</td><td>把现有特征进行组合，或互相计算，得到新的特征。比如说，我们有一列特征是速度，一列特征是距离，我们就可以通过让两列相处，创造新的特征:通过距离所花的时间。</td><td>从所有的特征中，选择出有意义，对模型有帮助的特征，以避免必须将所有特征都导入模型去训练的情况。</td></tr></tbody></table><h2 id="过滤法-Filter"><a href="#过滤法-Filter" class="headerlink" title="过滤法 Filter"></a>过滤法 Filter</h2><p>过滤方法通常用作预处理步骤，特征选择完全独立于任何机器学习算法。它是根据各种统计检验中的分数以及相关性的各项指标来选择特征。</p><p>过滤法的主要对象是:需要遍历特征或升维的算法们，而过滤法的主要目的是:在维持算法表现的前提下，帮助算法们降低计算成本。</p><h3 id="方差过滤"><a href="#方差过滤" class="headerlink" title="方差过滤"></a>方差过滤</h3><p>这是通过特征本身的方差来筛选特征的类。比如一个特征本身的方差很小，就表示样本在这个特征上基本没有差异，可能特征中的大多数值都一样，甚至整个特征的取值都相同，那这个特征对于样本区分没有什么作用。所以无论接下来的特征工程要做什么，都要优先消除方差为 0 的特征。</p><h3 id="相关性过滤"><a href="#相关性过滤" class="headerlink" title="相关性过滤"></a>相关性过滤</h3><p>我们希望选出与标签相关且有意义的特征，因为这样的特征能够为我们提供大量信息。如果特征与标签无关，那只会白白浪费我们的计算内存，可能还会给模型带来噪音。</p><h4 id="卡方过滤"><a href="#卡方过滤" class="headerlink" title="卡方过滤"></a>卡方过滤</h4><p>卡方过滤是专门针对离散型标签(即分类问题)的相关性过滤。<br>再结合 <strong>feature_selection.SelectKBest</strong> 这个可以输入”评分标准“来选出前 K 个分数最高的特征的类，我们可以借此除去最可能独立于标签，与我们分类目的无关的特征。</p><p>卡方检验的本质是推测两组数据之间的差异，其检验的原假设是”两组数据是相互独立的”。卡方检验返回卡方值和 P 值两个统计量，其中卡方值很难界定有效的范围，而 p 值，我们一般使用 0.01 或 0.05 作为显著性水平，即 p 值判断的边界.</p><h4 id="F-检验"><a href="#F-检验" class="headerlink" title="F 检验"></a>F 检验</h4><p>F 检验，又称 ANOVA，方差齐性检验，是用来捕捉每个特征与标签之间的线性关系的过滤方法。</p><p>F 检验的本质是寻找两组数据之间的线性关系，其原假设是”数据不存在显著的线性关系“。它返回 F 值和 p 值两个统计量。<br>和卡方过滤一样，我们希望选取 p 值小于 0.05 或 0.01 的特征，这些特征与标签时显著线性相关的，而 p 值大于 0.05 或 0.01 的特征则被我们认为是和标签没有显著线性关系的特征，应该被删除。</p><h4 id="互信息法"><a href="#互信息法" class="headerlink" title="互信息法"></a>互信息法</h4><p>互信息法是用来捕捉每个特征与标签之间的任意关系(包括线性和非线性关系)的过滤方法。<br>不过 互信息法比 F 检验更加强大，F 检验只能够找出线性关系，而互信息法可以找出任意关系。</p><h2 id="嵌入法-Embedded"><a href="#嵌入法-Embedded" class="headerlink" title="嵌入法 Embedded"></a>嵌入法 Embedded</h2><p>嵌入法是一种让算法自己决定使用哪些特征的方法，即特征选择和算法训练同时进行。在使用嵌入法时，我们先使 用某些机器学习的算法和模型进行训练，得到各个特征的权值系数，根据权值系数从大到小选择特征。</p><p><em>相比于过滤法，嵌入法的结果会更加精确到模型的效用本身，对于提高模型效力有更好的效果。并且，由于考虑特 征对模型的贡献，因此无关的特征(需要相关性过滤的特征)和无区分度的特征(需要方差过滤的特征)都会因为 缺乏对模型的贡献而被删除掉，可谓是过滤法的进化版。</em></p><p>嵌入法引入了算法来挑选特征，因此其计算速度也会和应用的算法有很大的关系。如果采用计算量很大，计算缓慢的算法，嵌入法本身也会非常耗时耗力。并且，在选择完毕之后，我们还是需要自己来评估模型。</p><p><strong>在算法本身很复杂的时候，过滤法的计算远远比嵌入法要 快，所以大型数据中，我们还是会优先考虑过滤法。</strong></p><h2 id="包装法-Wrapper"><a href="#包装法-Wrapper" class="headerlink" title="包装法 Wrapper"></a>包装法 Wrapper</h2><p>包装法也是一个特征选择和算法训练同时进行的方法，与嵌入法十分相似，它也是依赖于算法自身的选择,但不同的是，我们往往使用一个目标函数作为黑盒来帮 助我们选取特征，而不是自己输入某个评估指标或统计量的阈值。</p><p><strong>包装法要使用特征子集进行多次训练，因此它所需要的计算成本是最高的。</strong></p><p>最典型的目标函数是递归特征消除法(Recursive feature elimination, 简写为 RFE)。它是一种贪婪的优化算法， 旨在找到性能最佳的特征子集。 它反复创建模型，并在每次迭代时保留最佳特征或剔除最差特征，下一次迭代时， 它会使用上一次建模中没有被选中的特征来构建下一个模型，直到所有特征都耗尽为止。 然后，它根据自己保留或 剔除特征的顺序来对特征进行排名，最终选出一个最佳子集。包装法的效果是所有特征选择方法中最利于提升模型 表现的，它可以使用很少的特征达到很优秀的效果。除此之外，在特征数目相同时，包装法和嵌入法的效果能够匹 敌，不过它比嵌入法算得更见缓慢，所以也不适用于太大型的数据。相比之下， <strong>包装法是最能保证模型效果的特征 选择方法</strong> 。</p></div><div><ul class="post-copyright"><li class="post-copyright-author"><strong>本文作者： </strong>harumonia</li><li class="post-copyright-link"><strong>本文链接：</strong> <a href="https://blog.harumonia.moe/2019-09-08-Feature-Engineering/" title="浅谈特征工程 Feature  Engineering">https://blog.harumonia.moe/2019-09-08-Feature-Engineering/</a></li><li class="post-copyright-license"><strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/CC%20BY-NC-SA%204.0/4.0/" rel="noopener" target="_blank"><i class="fa fa-fw fa-creative-commons"></i>CC BY-NC-SA 4.0</a> 许可协议。转载请注明出处！</li></ul></div><footer class="post-footer"><div class="post-tags"><a href="/tags/%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/" rel="tag"><i class="fa fa-tag"></i> 特征工程</a></div><div class="post-nav"><div class="post-nav-item"><a href="/2019-09-01-Titanic-solution-via-RF/" rel="prev" title="使用随机森林解决"泰坦尼克幸存"问题(1)——小试牛刀"> <i class="fa fa-chevron-left"></i> 使用随机森林解决"泰坦尼克幸存"问题(1)——小试牛刀</div><div class="post-nav-item"><a href="/2019-09-26-21-Lessons-for-the-21st-Century/" rel="next" title="今日简史-笔记">今日简史-笔记 <i class="fa fa-chevron-right"></i></a></div></div></footer></article></div><div class="comments" id="valine-comments"></div><script>window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }</script></div><div class="toggle sidebar-toggle"><span class="toggle-line toggle-line-first"></span> <span class="toggle-line toggle-line-middle"></span> <span class="toggle-line toggle-line-last"></span></div><aside class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc">文章目录</li><li class="sidebar-nav-overview">站点概览</li></ul><div class="post-toc-wrap sidebar-panel"><div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86"><span class="nav-number">1.</span> <span class="nav-text">数据预处理</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%97%A0%E9%87%8F%E7%BA%B2%E5%8C%96"><span class="nav-number">1.1.</span> <span class="nav-text">无量纲化</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E5%BD%92%E4%B8%80%E5%8C%96"><span class="nav-number">1.1.1.</span> <span class="nav-text">数据归一化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E6%A0%87%E5%87%86%E5%8C%96"><span class="nav-number">1.1.2.</span> <span class="nav-text">数据标准化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%B0%8F%E7%BB%93"><span class="nav-number">1.1.3.</span> <span class="nav-text">小结</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BC%BA%E5%A4%B1%E5%80%BC-SimpleImputer"><span class="nav-number">1.2.</span> <span class="nav-text">缺失值 SimpleImputer</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BC%96%E7%A0%81%E4%B8%8E%E5%93%91%E5%8F%98%E9%87%8F"><span class="nav-number">1.3.</span> <span class="nav-text">编码与哑变量</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BC%96%E7%A0%81"><span class="nav-number">1.3.1.</span> <span class="nav-text">编码</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%93%91%E5%8F%98%E9%87%8F"><span class="nav-number">1.3.2.</span> <span class="nav-text">哑变量</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BA%8C%E5%80%BC%E5%8C%96%E4%B8%8E%E5%88%86%E6%AE%B5"><span class="nav-number">1.4.</span> <span class="nav-text">二值化与分段</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BA%8C%E5%80%BC%E5%8C%96"><span class="nav-number">1.4.1.</span> <span class="nav-text">二值化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%88%86%E6%AE%B5"><span class="nav-number">1.4.2.</span> <span class="nav-text">分段</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9-feature-selection"><span class="nav-number">2.</span> <span class="nav-text">特征选择 feature_selection</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%BF%87%E6%BB%A4%E6%B3%95-Filter"><span class="nav-number">2.1.</span> <span class="nav-text">过滤法 Filter</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%96%B9%E5%B7%AE%E8%BF%87%E6%BB%A4"><span class="nav-number">2.1.1.</span> <span class="nav-text">方差过滤</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%9B%B8%E5%85%B3%E6%80%A7%E8%BF%87%E6%BB%A4"><span class="nav-number">2.1.2.</span> <span class="nav-text">相关性过滤</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%8D%A1%E6%96%B9%E8%BF%87%E6%BB%A4"><span class="nav-number">2.1.2.1.</span> <span class="nav-text">卡方过滤</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#F-%E6%A3%80%E9%AA%8C"><span class="nav-number">2.1.2.2.</span> <span class="nav-text">F 检验</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BA%92%E4%BF%A1%E6%81%AF%E6%B3%95"><span class="nav-number">2.1.2.3.</span> <span class="nav-text">互信息法</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%B5%8C%E5%85%A5%E6%B3%95-Embedded"><span class="nav-number">2.2.</span> <span class="nav-text">嵌入法 Embedded</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8C%85%E8%A3%85%E6%B3%95-Wrapper"><span class="nav-number">2.3.</span> <span class="nav-text">包装法 Wrapper</span></a></li></ol></li></ol></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" alt="harumonia" src="https://harumona-blog.oss-cn-beijing.aliyuncs.com/blog/Ocabe.webp"><p class="site-author-name" itemprop="name">harumonia</p><div class="site-description" itemprop="description">lazy</div></div><div class="site-state-wrap motion-element"><nav class="site-state"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">102</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"><a href="/categories/"><span class="site-state-item-count">16</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"><a href="/tags/"><span class="site-state-item-count">54</span> <span class="site-state-item-name">标签</span></a></div></nav></div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/zxjlm" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;zxjlm" rel="noopener" target="_blank"><i class="fa fa-fw fa-fab fa-github"></i>GitHub</a> </span><span class="links-of-author-item"><a href="mailto:zxjlm233@gmail.com" title="E-Mail → mailto:zxjlm233@gmail.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-fab fa-envelope"></i>E-Mail</a></span></div></div><div class="back-to-top motion-element"><i class="fa fa-arrow-up"></i> <span>0%</span></div></div></aside><div id="sidebar-dimmer"></div></div></main><footer class="footer"><div class="footer-inner"><div class="copyright">&copy; 2017 – <span itemprop="copyrightYear">2020</span> <span class="with-love"><i class="fa fa-fab fa-asterisk"></i> </span><span class="author" itemprop="copyrightHolder">harumonia</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-area-chart"></i> </span><span class="post-meta-item-text">站点总字数：</span> <span title="站点总字数">339k</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-coffee"></i> </span><span class="post-meta-item-text">站点阅读时长 &asymp;</span> <span title="站点阅读时长">17:41</span></div></div></footer></div><script src="/lib/anime.min.js"></script><script src="//cdn.jsdelivr.net/npm/medium-zoom@1/dist/medium-zoom.min.js"></script><script src="//cdn.jsdelivr.net/npm/lozad@1/dist/lozad.min.js"></script><script src="/lib/velocity/velocity.min.js"></script><script src="/lib/velocity/velocity.ui.min.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/pisces.js"></script><script src="/js/next-boot.js"></script><script src="/js/local-search.js"></script><script>NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//cdnjs.cloudflare.com/ajax/libs/valine/1.3.10/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : true,
      appId      : 'MRbMQ94D5q51YRYIbsRF0kcH-gzGzoHsz',
      appKey     : 'A9JJBbjhfc9liCzCJgWIxpDa',
      placeholder: "Just go go",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : true,
      lang       : 'zh-cn' || 'zh-cn',
      path       : location.pathname,
      recordIP   : true,
      serverURLs : ''
    });
  }, window.Valine);
});</script><script async src="/js/cursor/fireworks.js"></script></body></html>