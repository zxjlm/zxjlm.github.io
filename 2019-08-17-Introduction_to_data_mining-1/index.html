<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><meta name="theme-color" content="#0078E7"><meta name="author" content="harumonia"><meta name="copyright" content="harumonia"><meta name="generator" content="Hexo 5.1.1"><meta name="theme" content="hexo-theme-yun"><title>Introduction to data mining(1) | Zaxon</title><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@900&amp;display=swap" media="print" onload='this.media="all"'><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/star-markdown-css@0.1.25/dist/yun/yun-markdown.min.css"><script src="//at.alicdn.com/t/font_1140697_j5gk85dg4pf.js" async></script><script src="https://cdn.jsdelivr.net/npm/scrollreveal/dist/scrollreveal.min.js" defer></script><script>document.addEventListener("DOMContentLoaded", () => {
  [".post-card",".post-content img"].forEach((target)=> {
    ScrollReveal().reveal(target);
  })
});</script><link id="light-prism-css" rel="stylesheet" href="https://cdn.jsdelivr.net/npm/prismjs@latest/themes/prism.css" media="(prefers-color-scheme:light)"><link id="dark-prism-css" rel="stylesheet" href="https://cdn.jsdelivr.net/npm/prismjs@latest/themes/prism-tomorrow.css" media="(prefers-color-scheme:dark)"><link rel="icon" href="/yun.svg"><link rel="mask-icon" href="/yun.svg" color="#0078E7"><link rel="alternate icon" href="/yun.ico"><link rel="preload" href="/css/hexo-theme-yun.css" as="style"><link rel="preload" href="/js/utils.js" as="script"><link rel="preload" href="/js/hexo-theme-yun.js" as="script"><link rel="prefetch" href="/js/sidebar.js" as="script"><link rel="preconnect" href="https://cdn.jsdelivr.net" crossorigin><script id="yun-config">const Yun = window.Yun || {};
    window.CONFIG = {"hostname":"blog.harumonia.moe","root":"/","title":"Zaxon-迷雾中的藏宝地","version":"1.6.1","mode":"auto","copycode":true,"page":{"isPost":true},"i18n":{"placeholder":"搜索...","empty":"找不到您查询的内容: ${query}","hits":"找到 ${hits} 条结果","hits_time":"找到 ${hits} 条结果（用时 ${time} 毫秒）"},"anonymous_image":"https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/avatar/none.jpg","say":{"api":"https://v1.hitokoto.cn","hitokoto":true},"fireworks":{"colors":["102, 167, 221","62, 131, 225","33, 78, 194"]}};</script><link rel="stylesheet" href="/css/hexo-theme-yun.css"><script src="/js/utils.js"></script><script src="/js/hexo-theme-yun.js"></script><link rel="preconnect" href="https://www.google-analytics.com" crossorigin><script async src="https://www.googletagmanager.com/gtag/js?id=G-EBNGE3F0F6"></script><script>function gtag(){dataLayer.push(arguments)}CONFIG.hostname===location.hostname&&(window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-EBNGE3F0F6"))</script><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0];t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}()</script><meta name="description" content="本篇是笔者在学习 “Introduction to data mining”(《数据挖掘导论》)的英文最新版所记录的一些学习笔记。 2020.10.10 更新 很可惜的是，在多次迁移的过程中，本章的图片都丢失了。 食之无味，弃之可惜。所以暂且先保留在这里，以后再补全吧。"><meta property="og:type" content="article"><meta property="og:title" content="Introduction to data mining(1)"><meta property="og:url" content="https://blog.harumonia.moe/2019-08-17-Introduction_to_data_mining-1/index.html"><meta property="og:site_name" content="Zaxon"><meta property="og:description" content="本篇是笔者在学习 “Introduction to data mining”(《数据挖掘导论》)的英文最新版所记录的一些学习笔记。 2020.10.10 更新 很可惜的是，在多次迁移的过程中，本章的图片都丢失了。 食之无味，弃之可惜。所以暂且先保留在这里，以后再补全吧。"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="http://www.harumonia.top/images/2019/08/17/image.md.png"><meta property="og:image" content="http://www.harumonia.top/images/2019/08/17/image04e5c16df6c5ea4b.md.png"><meta property="og:image" content="http://www.harumonia.top/images/2019/08/17/image1f4bfe8f69e2395b.md.png"><meta property="og:image" content="http://www.harumonia.top/images/2019/08/17/image59be1d41fb6ceff6.md.png"><meta property="og:image" content="http://www.harumonia.top/images/2019/08/17/imagea43b43449d9493db.md.png"><meta property="og:image" content="http://www.harumonia.top/images/2019/08/17/imageb9a8cc3bce2b2a12.md.png"><meta property="og:image" content="http://www.harumonia.top/images/2019/08/17/image418cf8e9aaebd1f7.md.png"><meta property="og:image" content="http://www.harumonia.top/images/2019/08/17/imagee59e593bbcfd3120.md.png"><meta property="og:image" content="http://www.harumonia.top/images/2019/08/17/image09c78ec0185a1ef1.png"><meta property="og:image" content="http://www.harumonia.top/images/2019/08/17/image4bfd8ac1d8b3156f.png"><meta property="og:image" content="http://www.harumonia.top/images/2019/08/17/imagec78fb1c028be231c.png"><meta property="og:image" content="http://www.harumonia.top/images/2019/08/17/image709b0bba0e810a01.png"><meta property="og:image" content="http://www.harumonia.top/images/2019/08/17/imagee4c8afe3e4e60ecf.png"><meta property="og:image" content="http://www.harumonia.top/images/2019/08/17/image950d41dec2581905.png"><meta property="og:image" content="http://www.harumonia.top/images/2019/08/17/image8002f990119f2a64.png"><meta property="og:image" content="http://www.harumonia.top/images/2019/08/17/imagefa2b122d3c3982db.png"><meta property="article:published_time" content="2019-08-17T09:14:20.000Z"><meta property="article:modified_time" content="2019-08-17T09:14:20.000Z"><meta property="article:author" content="harumonia"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="http://www.harumonia.top/images/2019/08/17/image.md.png"><script src="/js/ui/mode.js"></script></head><body><script defer src="https://cdn.jsdelivr.net/npm/animejs@latest"></script><script defer src="/js/ui/fireworks.js"></script><canvas class="fireworks"></canvas><div class="container"><a class="sidebar-toggle hty-icon-button" id="menu-btn"><div class="hamburger hamburger--spin" type="button"><span class="hamburger-box"><span class="hamburger-inner"></span></span></div></a><div class="sidebar-toggle sidebar-overlay"></div><aside class="sidebar"><script src="/js/sidebar.js"></script><ul class="sidebar-nav"><li class="sidebar-nav-item sidebar-nav-toc hty-icon-button sidebar-nav-active" data-target="post-toc-wrap" title="文章目录"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-list-ordered"></use></svg></li><li class="sidebar-nav-item sidebar-nav-overview hty-icon-button" data-target="site-overview-wrap" title="站点概览"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-passport-line"></use></svg></li></ul><div class="sidebar-panel" id="site-overview-wrap"><div class="site-info fix-top"><a class="site-author-avatar" href="/about/" title="harumonia"><img width="96" loading="lazy" src="https://harumona-blog.oss-cn-beijing.aliyuncs.com/blog/Ocabe.webp" alt="harumonia"></a><div class="site-author-name"><a href="/about/">harumonia</a></div><span class="site-name">Zaxon</span><sub class="site-subtitle">Find the key of soul</sub><div class="site-desciption">lazy</div></div><nav class="site-state"><a class="site-state-item hty-icon-button icon-home" href="/" title="首页"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-home-4-line"></use></svg></span></a><div class="site-state-item"><a href="/archives/" title="归档"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-archive-line"></use></svg></span><span class="site-state-item-count">128</span></a></div><div class="site-state-item"><a href="/categories/" title="分类"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-folder-2-line"></use></svg></span><span class="site-state-item-count">15</span></a></div><div class="site-state-item"><a href="/tags/" title="标签"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-price-tag-3-line"></use></svg></span><span class="site-state-item-count">69</span></a></div><a class="site-state-item hty-icon-button" href="/books" title="读书"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-book-2-line"></use></svg></span></a></nav><hr style="margin-bottom:.5rem"><div class="links-of-author"><a class="links-of-author-item hty-icon-button" rel="noopener" href="/atom.xml" title="RSS" target="_blank" style="color:orange"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-rss-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://qm.qq.com/cgi-bin/qm/qr?k=DSmoEtSKHITcV9pghYqqmSQ80-SPnPjm&amp;noverify=0" title="QQ" target="_blank" style="color:#12b7f5"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-qq-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://github.com/zxjlm" title="GitHub" target="_blank" style="color:#6e5494"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-github-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://www.douban.com/people/Zxj_Butterfly_m/" title="豆瓣" target="_blank" style="color:#072"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-douban-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://music.163.com/#/user/home?id=305617499" title="网易云音乐" target="_blank" style="color:#c20c0c"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-netease-cloud-music-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://space.bilibili.com/1801214" title="哔哩哔哩" target="_blank" style="color:#ff8eb3"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-bilibili-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://twitter.com/Harumonia1996" title="Twitter" target="_blank" style="color:#1da1f2"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-twitter-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="mailto:zxjlm233@gmail.com" title="E-Mail" target="_blank" style="color:#8e71c1"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-mail-line"></use></svg></a></div><hr style="margin:.5rem 1rem"><div class="links"><a class="links-item hty-icon-button" href="/links/" title="我的小伙伴们" style="color:#1e90ff"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-genderless-line"></use></svg></a></div><br><a class="links-item hty-icon-button" id="toggle-mode-btn" href="javascript:;" title="Mode" style="color:#f1cb64"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-contrast-2-line"></use></svg></a></div><div class="sidebar-panel sidebar-panel-active" id="post-toc-wrap"><div class="post-toc"><div class="post-toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%BB%AA%E8%AE%BA"><span class="toc-number">1.</span> <span class="toc-text">绪论</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98"><span class="toc-number">1.1.</span> <span class="toc-text">什么是数据挖掘</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E4%B8%8E%E7%9F%A5%E8%AF%86%E5%8F%91%E7%8E%B0"><span class="toc-number">1.1.1.</span> <span class="toc-text">数据挖掘与知识发现</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E8%A6%81%E8%A7%A3%E5%86%B3%E7%9A%84%E9%97%AE%E9%A2%98"><span class="toc-number">1.2.</span> <span class="toc-text">数据挖掘要解决的问题</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E7%9A%84%E4%BB%BB%E5%8A%A1"><span class="toc-number">1.3.</span> <span class="toc-text">数据挖掘的任务</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9B%9B%E5%A4%A7%E4%BB%BB%E5%8A%A1"><span class="toc-number">1.3.1.</span> <span class="toc-text">四大任务</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%A2%84%E6%B5%8B%E5%BB%BA%E6%A8%A1"><span class="toc-number">1.3.1.1.</span> <span class="toc-text">预测建模</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%B3%E7%B3%BB%E5%88%86%E6%9E%90"><span class="toc-number">1.3.1.2.</span> <span class="toc-text">关系分析</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90"><span class="toc-number">1.3.1.3.</span> <span class="toc-text">聚类分析</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B"><span class="toc-number">1.3.1.4.</span> <span class="toc-text">异常检测</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE"><span class="toc-number">2.</span> <span class="toc-text">数据</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B"><span class="toc-number">2.1.</span> <span class="toc-text">数据类型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B1%9E%E6%80%A7"><span class="toc-number">2.1.1.</span> <span class="toc-text">属性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E7%B1%BB%E5%9E%8B"><span class="toc-number">2.1.2.</span> <span class="toc-text">数据集的类型</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E4%B8%80%E8%88%AC%E7%89%B9%E6%80%A7"><span class="toc-number">2.1.2.1.</span> <span class="toc-text">数据集的一般特性</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%AE%B0%E5%BD%95%E6%95%B0%E6%8D%AE"><span class="toc-number">2.1.2.2.</span> <span class="toc-text">记录数据</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E5%9B%BE%E5%BD%A2%E7%9A%84%E6%95%B0%E6%8D%AE"><span class="toc-number">2.1.2.3.</span> <span class="toc-text">基于图形的数据</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9C%89%E5%BA%8F%E6%95%B0%E6%8D%AE"><span class="toc-number">2.1.2.4.</span> <span class="toc-text">有序数据</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A4%84%E7%90%86%E9%9D%9E%E8%AE%B0%E5%BD%95%E6%95%B0%E6%8D%AE"><span class="toc-number">2.1.2.5.</span> <span class="toc-text">处理非记录数据</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E8%B4%A8%E9%87%8F"><span class="toc-number">2.2.</span> <span class="toc-text">数据质量</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B5%8B%E9%87%8F%E5%92%8C%E6%95%B0%E6%8D%AE%E6%94%B6%E9%9B%86%E9%97%AE%E9%A2%98"><span class="toc-number">2.2.1.</span> <span class="toc-text">测量和数据收集问题</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B5%8B%E9%87%8F%E8%AF%AF%E5%B7%AE%E5%92%8C%E6%95%B0%E6%8D%AE%E6%94%B6%E9%9B%86%E9%94%99%E8%AF%AF-Measurement-and-Data-Collection-Errors"><span class="toc-number">2.2.1.1.</span> <span class="toc-text">测量误差和数据收集错误 Measurement and Data Collection Errors</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%99%AA%E5%A3%B0%E5%92%8C%E4%BC%AA%E8%B1%A1-Noise-and-Artifacts"><span class="toc-number">2.2.1.2.</span> <span class="toc-text">噪声和伪象 Noise and Artifacts</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%B2%BE%E5%BA%A6-%E5%81%8F%E5%80%9A%E5%92%8C%E5%87%86%E7%A1%AE%E7%8E%87-Precision-Bias-and-Accuracy"><span class="toc-number">2.2.1.3.</span> <span class="toc-text">精度\偏倚和准确率 Precision, Bias, and Accuracy</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%A6%BB%E7%BE%A4%E7%82%B9-Outliers"><span class="toc-number">2.2.1.4.</span> <span class="toc-text">离群点 Outliers</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%81%97%E6%BC%8F%E5%80%BC-Missing-Values"><span class="toc-number">2.2.1.5.</span> <span class="toc-text">遗漏值 Missing Values</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%8D%E4%B8%80%E8%87%B4%E7%9A%84%E5%80%BC-Inconsistent-Values"><span class="toc-number">2.2.1.6.</span> <span class="toc-text">不一致的值 Inconsistent Values</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%87%8D%E5%A4%8D%E6%95%B0%E6%8D%AE-Duplicate-Data"><span class="toc-number">2.2.1.7.</span> <span class="toc-text">重复数据 Duplicate Data</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%B3%E4%BA%8E%E5%BA%94%E7%94%A8%E7%9A%84%E9%97%AE%E9%A2%98"><span class="toc-number">2.2.2.</span> <span class="toc-text">关于应用的问题</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86-Data-Preprocessing"><span class="toc-number">2.3.</span> <span class="toc-text">数据预处理 Data Preprocessing</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%81%9A%E9%9B%86-Aggregation"><span class="toc-number">2.3.1.</span> <span class="toc-text">聚集 Aggregation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8A%BD%E6%A0%B7-Sampling-Approaches"><span class="toc-number">2.3.2.</span> <span class="toc-text">抽样 Sampling Approaches</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%8A%BD%E6%A0%B7%E6%96%B9%E6%B3%95-Sampling-Approaches"><span class="toc-number">2.3.2.1.</span> <span class="toc-text">抽样方法 Sampling Approaches</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B8%90%E8%BF%9B%E6%8A%BD%E6%A0%B7"><span class="toc-number">2.3.2.2.</span> <span class="toc-text">渐进抽样</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%B4%E5%BD%92%E7%BA%A6-Dimensionality-Reduction"><span class="toc-number">2.3.3.</span> <span class="toc-text">维归约 Dimensionality Reduction</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BB%B4%E7%81%BE%E9%9A%BE-The-Curse-of-Dimensionality"><span class="toc-number">2.3.3.1.</span> <span class="toc-text">维灾难 The Curse of Dimensionality</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BB%B4%E5%BD%92%E7%BA%A6%E7%9A%84%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E6%8A%80%E6%9C%AF-Linear-Algebra-Techniques-for-Dimensionality-Reduction"><span class="toc-number">2.3.3.2.</span> <span class="toc-text">维归约的线性代数技术 Linear Algebra Techniques for Dimensionality Reduction</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%89%B9%E5%BE%81%E5%AD%90%E9%9B%86%E9%80%89%E6%8B%A9-Feature-Subset-Selection"><span class="toc-number">2.3.4.</span> <span class="toc-text">特征子集选择 Feature Subset Selection</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%89%B9%E5%BE%81%E5%AD%90%E9%9B%86%E9%80%89%E6%8B%A9%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84"><span class="toc-number">2.3.4.1.</span> <span class="toc-text">特征子集选择体系结构</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%89%B9%E5%BE%81%E5%8A%A0%E6%9D%83-Feature-Weighting"><span class="toc-number">2.3.4.2.</span> <span class="toc-text">特征加权 Feature Weighting</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%89%B9%E5%BE%81%E5%88%9B%E5%BB%BA-Feature-Creation"><span class="toc-number">2.3.5.</span> <span class="toc-text">特征创建 Feature Creation</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96-Feature-Extraction"><span class="toc-number">2.3.5.1.</span> <span class="toc-text">特征提取 Feature Extraction</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%98%A0%E5%B0%84%E5%88%B0%E6%96%B0%E7%9A%84%E7%A9%BA%E9%97%B4-Mapping-the-Data-to-a-New-Space"><span class="toc-number">2.3.5.2.</span> <span class="toc-text">映射到新的空间 Mapping the Data to a New Space</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%89%B9%E5%BE%81%E6%9E%84%E9%80%A0-Feature-Construction"><span class="toc-number">2.3.5.3.</span> <span class="toc-text">特征构造 Feature Construction</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%A6%BB%E6%95%A3%E5%8C%96%E5%92%8C%E4%BA%8C%E5%85%83%E5%8C%96-Discretization-and-Binarization"><span class="toc-number">2.3.6.</span> <span class="toc-text">离散化和二元化 Discretization and Binarization</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BA%8C%E5%85%83%E5%8C%96"><span class="toc-number">2.3.6.1.</span> <span class="toc-text">二元化</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%BF%9E%E7%BB%AD%E5%B1%9E%E6%80%A7%E7%A6%BB%E6%95%A3%E5%8C%96"><span class="toc-number">2.3.6.2.</span> <span class="toc-text">连续属性离散化</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E9%9D%9E%E7%9B%91%E7%9D%A3%E7%A6%BB%E6%95%A3%E5%8C%96-unSupervised-Discretization"><span class="toc-number">2.3.6.2.1.</span> <span class="toc-text">非监督离散化 unSupervised Discretization</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%9B%91%E7%9D%A3%E7%A6%BB%E6%95%A3%E5%8C%96-Supervised-Discretization"><span class="toc-number">2.3.6.2.2.</span> <span class="toc-text">监督离散化 Supervised Discretization</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%B7%E6%9C%89%E8%BF%87%E5%A4%9A%E5%80%BC%E7%9A%84%E5%88%86%E7%B1%BB%E5%B1%9E%E6%80%A7"><span class="toc-number">2.3.6.3.</span> <span class="toc-text">具有过多值的分类属性</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8F%98%E9%87%8F%E5%8F%98%E6%8D%A2-Variable-Tlansformation"><span class="toc-number">2.3.7.</span> <span class="toc-text">变量变换 Variable Tlansformation</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%AE%80%E5%8D%95%E5%87%BD%E6%95%B0-Simple-Functions"><span class="toc-number">2.3.7.1.</span> <span class="toc-text">简单函数 Simple Functions</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%A7%84%E8%8C%83%E5%8C%96%E5%92%8C%E6%A0%87%E5%87%86%E5%8C%96-Normalization-or-Standardization"><span class="toc-number">2.3.7.2.</span> <span class="toc-text">规范化和标准化 Normalization or Standardization</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9B%B8%E4%BC%BC%E6%80%A7%E5%92%8C%E7%9B%B8%E5%BC%82%E6%80%A7%E7%9A%84%E5%BA%A6%E9%87%8F-Measures-of-Similarity-and-Dissimilarity"><span class="toc-number">2.4.</span> <span class="toc-text">相似性和相异性的度量 Measures of Similarity and Dissimilarity</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E7%A1%80-Basics"><span class="toc-number">2.4.1.</span> <span class="toc-text">基础 Basics</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89-Definitions"><span class="toc-number">2.4.1.1.</span> <span class="toc-text">定义 Definitions</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8F%98%E6%8D%A2"><span class="toc-number">2.4.1.2.</span> <span class="toc-text">变换</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%AE%80%E5%8D%95%E5%B1%9E%E6%80%A7%E4%B9%8B%E9%97%B4%E7%9A%84%E7%9B%B8%E4%BC%BC%E5%BA%A6%E5%92%8C%E7%9B%B8%E5%BC%82%E5%BA%A6"><span class="toc-number">2.4.1.3.</span> <span class="toc-text">简单属性之间的相似度和相异度</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%AF%B9%E8%B1%A1%E4%B9%8B%E9%97%B4%E7%9A%84%E7%9B%B8%E5%BC%82%E5%BA%A6-Dissimilarities-between-Data-Objects"><span class="toc-number">2.4.1.4.</span> <span class="toc-text">数据对象之间的相异度 Dissimilarities between Data Objects</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%AF%B9%E8%B1%A1%E4%B9%8B%E9%97%B4%E7%9A%84%E7%9B%B8%E4%BC%BC%E5%BA%A6-Similarities-between-Data-Objects"><span class="toc-number">2.4.1.5.</span> <span class="toc-text">数据对象之间的相似度 Similarities between Data Objects</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%82%BB%E8%BF%91%E6%80%A7%E5%BA%A6%E9%87%8F%E7%9A%84%E4%BE%8B%E5%AD%90-Examples-of-Proximity-Measures"><span class="toc-number">2.4.1.6.</span> <span class="toc-text">邻近性度量的例子 Examples of Proximity Measures</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%BA%8C%E5%85%83%E6%95%B0%E6%8D%AE%E7%9A%84%E7%9B%B8%E4%BC%BC%E6%80%A7%E5%BA%A6%E9%87%8F"><span class="toc-number">2.4.1.6.1.</span> <span class="toc-text">二元数据的相似性度量</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%BD%99%E5%BC%A6%E7%9B%B8%E4%BC%BC%E5%BA%A6-Cosine-Similarity"><span class="toc-number">2.4.1.6.2.</span> <span class="toc-text">余弦相似度 Cosine Similarity</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%B9%BF%E4%B9%89-Jaccard-%E7%B3%BB%E6%95%B0-Extended-Jaccard-Coefficient-Tanimoto-Coefficient"><span class="toc-number">2.4.1.6.3.</span> <span class="toc-text">广义 Jaccard 系数 Extended Jaccard Coefficient (Tanimoto Coefficient)</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%9B%B8%E5%85%B3%E6%80%A7-Correlation"><span class="toc-number">2.4.1.6.4.</span> <span class="toc-text">相关性 Correlation</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%82%BB%E8%BF%91%E5%BA%A6%E8%AE%A1%E7%AE%97%E9%97%AE%E9%A2%98"><span class="toc-number">2.4.1.7.</span> <span class="toc-text">邻近度计算问题</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%B7%9D%E7%A6%BB%E5%BA%A6%E9%87%8F%E7%9A%84%E6%A0%87%E5%87%86%E5%8C%96%E5%92%8C%E7%9B%B8%E5%85%B3%E6%80%A7"><span class="toc-number">2.4.1.7.1.</span> <span class="toc-text">距离度量的标准化和相关性</span></a></li></ol></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#wander-season"><span class="toc-number">3.</span> <span class="toc-text">wander season</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#kaggle"><span class="toc-number">3.1.</span> <span class="toc-text">kaggle</span></a></li></ol></li></ol></div></div></div></aside><main class="sidebar-translate" id="content"><div id="post"><article class="hty-card post-block" itemscope itemtype="https://schema.org/Article"><link itemprop="mainEntityOfPage" href="https://blog.harumonia.moe/2019-08-17-Introduction_to_data_mining-1/"><span hidden itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="name" content="harumonia"><meta itemprop="description"></span><span hidden itemprop="publisher" itemscope itemtype="https://schema.org/Organization"><meta itemprop="name" content="Zaxon"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">Introduction to data mining(1)</h1><div class="post-meta"><div class="post-time" style="display:inline-block"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-calendar-line"></use></svg></span><time title="创建时间：2019-08-17 09:14:20" itemprop="dateCreated datePublished" datetime="2019-08-17T09:14:20+00:00">2019-08-17</time></div><div class="post-classify"><span class="post-category"><span class="post-meta-item-icon" style="margin-right:3px"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-folder-line"></use></svg></span><span itemprop="about" itemscope itemtype="https://schema.org/Thing"><a class="category-item" href="/categories/%E6%BA%90%E6%B5%81%E6%B8%85%E6%B3%89/" style="--text-color:var(--hty-text-color)" itemprop="url" rel="index"><span itemprop="text">源流清泉</span></a></span> > <span itemprop="about" itemscope itemtype="https://schema.org/Thing"><a class="category-item" href="/categories/%E6%BA%90%E6%B5%81%E6%B8%85%E6%B3%89/Data-Mining/" style="--text-color:var(--hty-text-color)" itemprop="url" rel="index"><span itemprop="text">Data Mining</span></a></span></span></div><div class="post-author"><span class="author-name">harumonia</span></div></div></header><section class="post-body" itemprop="articleBody"><div class="post-content markdown-body" style="--smc-primary:#0078E7"><p>本篇是笔者在学习 “Introduction to data mining”(《数据挖掘导论》)的英文最新版所记录的一些学习笔记。</p><p>2020.10.10 更新</p><p>很可惜的是，在多次迁移的过程中，本章的图片都丢失了。</p><p>食之无味，弃之可惜。所以暂且先保留在这里，以后再补全吧。</p><a id="more"></a><h1 id="绪论"><a href="#绪论" class="headerlink" title="绪论"></a>绪论</h1><h2 id="什么是数据挖掘"><a href="#什么是数据挖掘" class="headerlink" title="什么是数据挖掘"></a>什么是数据挖掘</h2><p>数据挖掘是在大型数据库中，自动发现有用信息的过程。</p><blockquote><p>Data mining is the processof automatically discoveringuseful information in large data repositories.</p></blockquote><h3 id="数据挖掘与知识发现"><a href="#数据挖掘与知识发现" class="headerlink" title="数据挖掘与知识发现"></a>数据挖掘与知识发现</h3><p><a target="_blank" rel="noopener" href="http://www.harumonia.top/image/JVRe"><img src="http://www.harumonia.top/images/2019/08/17/image.md.png" alt="image.md.png" loading="lazy"></a></p><h2 id="数据挖掘要解决的问题"><a href="#数据挖掘要解决的问题" class="headerlink" title="数据挖掘要解决的问题"></a>数据挖掘要解决的问题</h2><ul><li>可伸缩</li><li>高维性</li><li>异种数据和复杂数据</li><li>数据的所有权与分布</li><li>非传统的分析</li></ul><h2 id="数据挖掘的任务"><a href="#数据挖掘的任务" class="headerlink" title="数据挖掘的任务"></a>数据挖掘的任务</h2><ul><li>预测变量<blockquote><p>The objective of thesetasks is to predict the value of a par- ticular attribute basedon the valuesof other attributes. The attribute to be predicted is commonly known as the target or dependent vari- able, while the attributes used for making the prediction are known as the explanatory or independent variables.</p></blockquote></li><li>描述任务<blockquote><p>Here, the objective is to derive patterns (correlations, trends, clusters, trajectories, and anomalies) that summarize the un- derlying relationships in data. Descriptive data mining tasks are often exploratory in nature and frequently require postprocessingtechniques to validate and explain the results</p></blockquote></li></ul><h3 id="四大任务"><a href="#四大任务" class="headerlink" title="四大任务"></a>四大任务</h3><h4 id="预测建模"><a href="#预测建模" class="headerlink" title="预测建模"></a>预测建模</h4><ul><li>分类：用于预测 <strong>离散</strong> 的目标变量 (二值型)</li><li>回归：…… <strong>连续</strong> ……</li></ul><p><em>应用</em> ：可以用来确定顾客对产品促销的反应、预测地球生态系统的扰动、根据检查结果判断病人是否具有某种疾病<br><em>典型案例</em> ：预测花的类型</p><h4 id="关系分析"><a href="#关系分析" class="headerlink" title="关系分析"></a>关系分析</h4><p>用来发现描述数据中强关联特征的模式<br><em>应用</em> : 找出具有相关功能的基因组、识别用户一起访问的 Web 页面、理解地球气候系统不同元素之间的联系<br><em>典型案例</em> : 购物篮分析(牛奶——尿布)</p><h4 id="聚类分析"><a href="#聚类分析" class="headerlink" title="聚类分析"></a>聚类分析</h4><p>发现紧密相关的 <strong>观测值组群</strong> ，使得与属于不同簇的观测值相比,属于同一簇的观测值尽可能地相似.</p><p><em>应用</em> : 对相关的客户分组 , 找出显著影响地球气候的海洋区域以及压缩数据等<br><em>典型案例</em> : 文档聚类(词之间的相似性)</p><h4 id="异常检测"><a href="#异常检测" class="headerlink" title="异常检测"></a>异常检测</h4><p>识别特征显著不同于其他数据的观测值,这样的值称为 <strong>异常点</strong> 或 <strong>离群点</strong> .<br>好的异常检测器必然具有高检测率和低误报率.</p><p><em>应用</em> : 检测欺诈\网络攻击\疾病的不寻常模式\生态系统扰动<br><em>典型案例</em> :信用卡欺诈检测</p><h1 id="数据"><a href="#数据" class="headerlink" title="数据"></a>数据</h1><h2 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h2><p>数据对象 : 记录\点\向量\模式\事件\案例\样本\观测或实体</p><h3 id="属性"><a href="#属性" class="headerlink" title="属性"></a>属性</h3><p>四种属性类型:标称 序数 区间 比率<br><a target="_blank" rel="noopener" href="http://www.harumonia.top/image/N7Zp"><img src="http://www.harumonia.top/images/2019/08/17/image04e5c16df6c5ea4b.md.png" alt="image04e5c16df6c5ea4b.md.png" loading="lazy"></a><br>标称和序数统称 <strong>分类的</strong> (categorical) 或 <strong>定性的</strong> (qualitative) 属性.顾名思义,定性属性(如雇员 ID)不具有数的大部分性质,应当像对待符号一样对待他们.其余两种属性,即区间和比率,统称 <strong>定量的</strong> (quantitative) 或 <strong>数值的</strong> (numeric) 属性,用数表示,并且具有数的大部分性质.</p><pre><code>                        定义属性层次的变换</code></pre><p><a target="_blank" rel="noopener" href="http://www.harumonia.top/image/NNYg"><img src="http://www.harumonia.top/images/2019/08/17/image1f4bfe8f69e2395b.md.png" alt="image1f4bfe8f69e2395b.md.png" loading="lazy"></a></p><h3 id="数据集的类型"><a href="#数据集的类型" class="headerlink" title="数据集的类型"></a>数据集的类型</h3><ul><li>记录数据</li><li>基于图形的数据</li><li>有序的数据</li></ul><h4 id="数据集的一般特性"><a href="#数据集的一般特性" class="headerlink" title="数据集的一般特性"></a>数据集的一般特性</h4><ul><li>维度<br>对象具有的属性的数目.分析高维数据有时会陷入 <strong>维灾难(curse of dimensionality)</strong> 所以要先预处理.</li><li>稀疏性</li><li>分辨率</li></ul><h4 id="记录数据"><a href="#记录数据" class="headerlink" title="记录数据"></a>记录数据</h4><ul><li>事物数据或购物篮数据</li><li>数据矩阵</li><li>稀疏数据矩阵</li></ul><p><a target="_blank" rel="noopener" href="http://www.harumonia.top/image/Nqn6"><img src="http://www.harumonia.top/images/2019/08/17/image59be1d41fb6ceff6.md.png" alt="image59be1d41fb6ceff6.md.png" loading="lazy"></a></p><h4 id="基于图形的数据"><a href="#基于图形的数据" class="headerlink" title="基于图形的数据"></a>基于图形的数据</h4><p>这里考虑两种特殊情况:图形捕获数据对象之间的联系\数据对象本身用图形表示</p><h4 id="有序数据"><a href="#有序数据" class="headerlink" title="有序数据"></a>有序数据</h4><p>属性具有涉及时间或空间序的联系</p><ul><li>时序数据</li><li>序列数据</li><li>时间序列数据</li><li>空间数据</li></ul><h4 id="处理非记录数据"><a href="#处理非记录数据" class="headerlink" title="处理非记录数据"></a>处理非记录数据</h4><h2 id="数据质量"><a href="#数据质量" class="headerlink" title="数据质量"></a>数据质量</h2><p>(1)数据质量问题的检测和纠正<br>(2)使用可以容忍低质量数据的算法</p><h3 id="测量和数据收集问题"><a href="#测量和数据收集问题" class="headerlink" title="测量和数据收集问题"></a>测量和数据收集问题</h3><ul><li>噪声</li><li>伪象</li><li>偏倚</li><li>精度</li><li>准确率</li></ul><h4 id="测量误差和数据收集错误-Measurement-and-Data-Collection-Errors"><a href="#测量误差和数据收集错误-Measurement-and-Data-Collection-Errors" class="headerlink" title="测量误差和数据收集错误 Measurement and Data Collection Errors"></a>测量误差和数据收集错误 Measurement and Data Collection Errors</h4><p>通过人工干预来纠正(比如在数据录入的时候)</p><h4 id="噪声和伪象-Noise-and-Artifacts"><a href="#噪声和伪象-Noise-and-Artifacts" class="headerlink" title="噪声和伪象 Noise and Artifacts"></a>噪声和伪象 Noise and Artifacts</h4><p>噪声 Noise : 通常用于包含时间或空间分量的数据，这种情况下，通常可以使用信号或图像处理技术来降低噪声<br>伪象 Artifacts : 确定性失真</p><pre><code>鲁棒算法：
    在噪声干扰下也能产生可以接受的结果。</code></pre><h4 id="精度-偏倚和准确率-Precision-Bias-and-Accuracy"><a href="#精度-偏倚和准确率-Precision-Bias-and-Accuracy" class="headerlink" title="精度\偏倚和准确率 Precision, Bias, and Accuracy"></a>精度\偏倚和准确率 Precision, Bias, and Accuracy</h4><p>精度 Precision : (同一个量的)重复测量值之间的接近程度<br>偏倚 Bias : 测量值与被测量值之间的系统的变差<br>准确率 Accuracy :被测量的测量值与实际值之间的接近度</p><pre><code>准确度依赖于精度和偏倚</code></pre><p>异常值 Outliers</p><h4 id="离群点-Outliers"><a href="#离群点-Outliers" class="headerlink" title="离群点 Outliers"></a>离群点 Outliers</h4><p>与典型值不同的值，即“异常”<br>区别噪声和离群点</p><h4 id="遗漏值-Missing-Values"><a href="#遗漏值-Missing-Values" class="headerlink" title="遗漏值 Missing Values"></a>遗漏值 Missing Values</h4><p>条件选择型填空常见<br>处理方法：</p><ul><li>删除数据对象或属性</li><li>估计遗漏值 平滑——连续</li><li>在分析时忽略遗漏值</li></ul><h4 id="不一致的值-Inconsistent-Values"><a href="#不一致的值-Inconsistent-Values" class="headerlink" title="不一致的值 Inconsistent Values"></a>不一致的值 Inconsistent Values</h4><p>错误的值、不在允许范围内的值</p><h4 id="重复数据-Duplicate-Data"><a href="#重复数据-Duplicate-Data" class="headerlink" title="重复数据 Duplicate Data"></a>重复数据 Duplicate Data</h4><h3 id="关于应用的问题"><a href="#关于应用的问题" class="headerlink" title="关于应用的问题"></a>关于应用的问题</h3><p>理想情况下,数据集附有描述数据的文档</p><h2 id="数据预处理-Data-Preprocessing"><a href="#数据预处理-Data-Preprocessing" class="headerlink" title="数据预处理 Data Preprocessing"></a>数据预处理 Data Preprocessing</h2><p>分为两大类:选择分析所需要的数据对象和属性 以及 创建/改变属性.</p><blockquote><p>根据习惯,使用特征(feature)或变量(variable)指代属性</p></blockquote><h3 id="聚集-Aggregation"><a href="#聚集-Aggregation" class="headerlink" title="聚集 Aggregation"></a>聚集 Aggregation</h3><p>将两个或多个对象合并成单个对象</p><p><strong>定量</strong> 属性(如价格)通常通过求和或求平均值进行聚集<br><strong>定性</strong> 属性(如商品)可以忽略或汇总成在一个商店销售的所有商品的集合</p><p>聚集的动机有多种:<br>首先,数据归约导致的较小数据集需要较少的内存和处理时间,因此,可以使用开销更大的数据挖掘算法.<br>其次,通过高层而不是低层数据视图,聚集起到了范围或标度转换的作用.<br>最后,对象或属性群的行为通常比单对象或属性的行为更稳定.</p><blockquote><p>聚集的缺点可能是丢失有趣的细节(如极值)</p></blockquote><h3 id="抽样-Sampling-Approaches"><a href="#抽样-Sampling-Approaches" class="headerlink" title="抽样 Sampling Approaches"></a>抽样 Sampling Approaches</h3><p>抽样是一种选择数据对象子集进行分析的常用方法.<br>在统计学中,抽样长期用于数据的事先调查和最终的数据分析.</p><p><strong>有效抽样的</strong> 原理:<br>如果样本是有代表性的,则使用样本与使用整个数据集的效果几乎一样.<br>而样本是有代表性的,前提是它近似地具有与原数据集相同的(感兴趣的)性质</p><h4 id="抽样方法-Sampling-Approaches"><a href="#抽样方法-Sampling-Approaches" class="headerlink" title="抽样方法 Sampling Approaches"></a>抽样方法 Sampling Approaches</h4><ul><li><p>简单随机抽样</p><ul><li>无放回抽样</li><li>有放回抽样</li></ul></li><li><p>分层抽样</p></li></ul><h4 id="渐进抽样"><a href="#渐进抽样" class="headerlink" title="渐进抽样"></a>渐进抽样</h4><p>从一个小样本开始,增加样本容量直到得到足够容量的样本.</p><h3 id="维归约-Dimensionality-Reduction"><a href="#维归约-Dimensionality-Reduction" class="headerlink" title="维归约 Dimensionality Reduction"></a>维归约 Dimensionality Reduction</h3><p>好处:</p><ul><li>如果维度较低,许多数据挖掘的算法的效果会更好.</li><li>可以使模型更容易理解</li><li>可以更容易让数据可视化</li><li>降低了数据挖掘算法的时间和内存需求</li></ul><blockquote><p>通过选择旧属性的子集得到新属性,这种归约称为 <strong>特征子集选择</strong> 或 <strong>特征选择</strong></p></blockquote><h4 id="维灾难-The-Curse-of-Dimensionality"><a href="#维灾难-The-Curse-of-Dimensionality" class="headerlink" title="维灾难 The Curse of Dimensionality"></a>维灾难 The Curse of Dimensionality</h4><p>维灾难:随着数据维度的增加,许多数据分析变得非常困难.特别是随着维度增加,数据在它所占据的空间中越来越稀疏.</p><p>结果是对于高维数据,许多分类和聚类算法(以及其他数据分析算法)都麻烦缠身–分类准确率低,聚类质量下降</p><h4 id="维归约的线性代数技术-Linear-Algebra-Techniques-for-Dimensionality-Reduction"><a href="#维归约的线性代数技术-Linear-Algebra-Techniques-for-Dimensionality-Reduction" class="headerlink" title="维归约的线性代数技术 Linear Algebra Techniques for Dimensionality Reduction"></a>维归约的线性代数技术 Linear Algebra Techniques for Dimensionality Reduction</h4><p>将数据从高维 <strong>投影</strong> 到低维空间,特别是对于 <strong>连续</strong> 数据</p><ul><li>主成分分析 Principal Components Analysis (PCA)<br>用于连续属性的线性代数技术,她找出新的属性(主成分),这些属性数原属性的线性组合,是相互 <strong>正交的 (orthogonal)</strong>,并且捕获了数据的最大变差.</li><li>奇异值分解 Singular Value Decomposition (SVD)</li></ul><h3 id="特征子集选择-Feature-Subset-Selection"><a href="#特征子集选择-Feature-Subset-Selection" class="headerlink" title="特征子集选择 Feature Subset Selection"></a>特征子集选择 Feature Subset Selection</h3><p>降低维度的另一种方法是只是用特征的一个子集</p><p><strong>Redundant features</strong> (冗余特征) duplicate much or all of the information contained in one or more other attributes.</p><p><strong>Irrelevant features</strong> (不相干特征) Oontain almost no useful information for the data mining task at hand.</p><p>冗余和不相干特征可能降低分类的准确率,影响所发现的聚类的质量.</p><p>特征选择的理想方法:将所有可能的特征子集作为感兴趣的数据挖掘算法的输入,然后选择产生最好结果的子集.</p><p>三种标准的特征选择方法:嵌入,过滤,包装</p><ul><li>嵌入方法 Embedded approaches<br>作为数据挖掘算法的一部分</li><li>过滤方法 Filter approaches<br>使用某种独立于数据挖掘的方法</li><li>包装方法 Wrapper approaches<br>这些方法将目标数据挖掘算法作为黑盒,使用类似与前面介绍的理想算法</li></ul><h4 id="特征子集选择体系结构"><a href="#特征子集选择体系结构" class="headerlink" title="特征子集选择体系结构"></a>特征子集选择体系结构</h4><p>子集评估度量,控制新的特征子集产生的搜索策略,停止搜索判断,验证过程</p><p><a target="_blank" rel="noopener" href="http://www.harumonia.top/image/NsSt"><img src="http://www.harumonia.top/images/2019/08/17/imagea43b43449d9493db.md.png" alt="imagea43b43449d9493db.md.png" loading="lazy"></a></p><h4 id="特征加权-Feature-Weighting"><a href="#特征加权-Feature-Weighting" class="headerlink" title="特征加权 Feature Weighting"></a>特征加权 Feature Weighting</h4><h3 id="特征创建-Feature-Creation"><a href="#特征创建-Feature-Creation" class="headerlink" title="特征创建 Feature Creation"></a>特征创建 Feature Creation</h3><h4 id="特征提取-Feature-Extraction"><a href="#特征提取-Feature-Extraction" class="headerlink" title="特征提取 Feature Extraction"></a>特征提取 Feature Extraction</h4><p>最常使用的特征提取都是高度针对具体领域的<br>一旦数据挖掘用于一个新的领域,一个关键任务就是开发新的特征和特征提取方法</p><h4 id="映射到新的空间-Mapping-the-Data-to-a-New-Space"><a href="#映射到新的空间-Mapping-the-Data-to-a-New-Space" class="headerlink" title="映射到新的空间 Mapping the Data to a New Space"></a>映射到新的空间 Mapping the Data to a New Space</h4><p>使用一种完全不同的视角挖掘数据可能揭示出重要和有趣的特征.</p><p>傅里叶变换 Fourier transform</p><blockquote><p>对于时间序列和其他类型的数据,<strong>小波变换 wavelet transform</strong> 也非常有用</p></blockquote><h4 id="特征构造-Feature-Construction"><a href="#特征构造-Feature-Construction" class="headerlink" title="特征构造 Feature Construction"></a>特征构造 Feature Construction</h4><p>一个或多个由元特征构造的新特征可能比原特征更有用</p><h3 id="离散化和二元化-Discretization-and-Binarization"><a href="#离散化和二元化-Discretization-and-Binarization" class="headerlink" title="离散化和二元化 Discretization and Binarization"></a>离散化和二元化 Discretization and Binarization</h3><h4 id="二元化"><a href="#二元化" class="headerlink" title="二元化"></a>二元化</h4><p>如果有 m 个分类值,则将每个原始值唯一的赋予区间[0,m-1]中的一个整数.</p><p>这样的变换可能导致复杂化,如无意之中建立了转换后的属性之间的联系.</p><p>关联分析需要非对称的二元属性,其中只有属性的出现(值为 1)才是重要的.</p><p>对于关联问题,可能需要用两个非对称的二元属性替换单个二元属性.</p><h4 id="连续属性离散化"><a href="#连续属性离散化" class="headerlink" title="连续属性离散化"></a>连续属性离散化</h4><p>两个子任务:决定需多少个分类值,以及确定如何将连续属性值映射到这些分类值.</p><p>离散化问题就是决定选择多少个分割点和确定分割点位置的问题.</p><h5 id="非监督离散化-unSupervised-Discretization"><a href="#非监督离散化-unSupervised-Discretization" class="headerlink" title="非监督离散化 unSupervised Discretization"></a>非监督离散化 unSupervised Discretization</h5><p>聚类?</p><h5 id="监督离散化-Supervised-Discretization"><a href="#监督离散化-Supervised-Discretization" class="headerlink" title="监督离散化 Supervised Discretization"></a>监督离散化 Supervised Discretization</h5><p>基于统计学的方法用每个属性值来分区间,并通过过类似于根据统计检验得出的相邻区间来创建较大的区间.</p><p>基于熵的方法是最有前途的离散化方法之一.<br><a target="_blank" rel="noopener" href="http://www.harumonia.top/image/NHsI"><img src="http://www.harumonia.top/images/2019/08/17/imageb9a8cc3bce2b2a12.md.png" alt="imageb9a8cc3bce2b2a12.md.png" loading="lazy"></a></p><p><a target="_blank" rel="noopener" href="http://www.harumonia.top/image/NfMY"><img src="http://www.harumonia.top/images/2019/08/17/image418cf8e9aaebd1f7.md.png" alt="image418cf8e9aaebd1f7.md.png" loading="lazy"></a></p><h4 id="具有过多值的分类属性"><a href="#具有过多值的分类属性" class="headerlink" title="具有过多值的分类属性"></a>具有过多值的分类属性</h4><h3 id="变量变换-Variable-Tlansformation"><a href="#变量变换-Variable-Tlansformation" class="headerlink" title="变量变换 Variable Tlansformation"></a>变量变换 Variable Tlansformation</h3><p>指用于变量的所有值的变换</p><p>简单函数变换和规范化</p><h4 id="简单函数-Simple-Functions"><a href="#简单函数-Simple-Functions" class="headerlink" title="简单函数 Simple Functions"></a>简单函数 Simple Functions</h4><blockquote><p>A variable transformation refers to a transformation that is applied to all thevaluesofavariable.</p></blockquote><p>在统计学中,变量变换常用来将不具有高斯分布的数据变换成具有高斯分布的数据.<br>在数据挖掘中,可以用来压缩值域</p><h4 id="规范化和标准化-Normalization-or-Standardization"><a href="#规范化和标准化-Normalization-or-Standardization" class="headerlink" title="规范化和标准化 Normalization or Standardization"></a>规范化和标准化 Normalization or Standardization</h4><p>使整个值得集合具有特定的性质</p><h2 id="相似性和相异性的度量-Measures-of-Similarity-and-Dissimilarity"><a href="#相似性和相异性的度量-Measures-of-Similarity-and-Dissimilarity" class="headerlink" title="相似性和相异性的度量 Measures of Similarity and Dissimilarity"></a>相似性和相异性的度量 Measures of Similarity and Dissimilarity</h2><p>许多情况下,一旦计算出相似性或相异性就不再需要原始数据了.</p><p>使用属于 <strong>邻近度 proximity</strong> 来表示相似性或相异性</p><h3 id="基础-Basics"><a href="#基础-Basics" class="headerlink" title="基础 Basics"></a>基础 Basics</h3><h4 id="定义-Definitions"><a href="#定义-Definitions" class="headerlink" title="定义 Definitions"></a>定义 Definitions</h4><blockquote><p>the similarity between two objects is a numerical measure of the degreeto which the two objects are alike.<br>The dissimilarity betweentwo objects is a numerical measureof the de- gree to which the two objects are different.</p></blockquote><p>通常术语”距离”用作相异度的同义词.<br>有时相异度在[0,1]中取值,但是相异度在 0 和 ♾ 之间取值也很常见.</p><h4 id="变换"><a href="#变换" class="headerlink" title="变换"></a>变换</h4><p>通常使用变换将相似度从相异转为相反.</p><h4 id="简单属性之间的相似度和相异度"><a href="#简单属性之间的相似度和相异度" class="headerlink" title="简单属性之间的相似度和相异度"></a>简单属性之间的相似度和相异度</h4><p><a target="_blank" rel="noopener" href="http://www.harumonia.top/image/NlDw"><img src="http://www.harumonia.top/images/2019/08/17/imagee59e593bbcfd3120.md.png" alt="imagee59e593bbcfd3120.md.png" loading="lazy"></a></p><h4 id="数据对象之间的相异度-Dissimilarities-between-Data-Objects"><a href="#数据对象之间的相异度-Dissimilarities-between-Data-Objects" class="headerlink" title="数据对象之间的相异度 Dissimilarities between Data Objects"></a>数据对象之间的相异度 Dissimilarities between Data Objects</h4><ul><li>距离<br><strong>欧几里得距离</strong> Euclidean distance<br><a target="_blank" rel="noopener" href="http://www.harumonia.top/image/NrLi"><img src="http://www.harumonia.top/images/2019/08/17/image09c78ec0185a1ef1.png" alt="image09c78ec0185a1ef1.png" loading="lazy"></a><br>其中,n 是维数,而 <strong>x</strong> k 和 <strong>y</strong> k 分别是 x 和 y 的第 k 个属性值(分量)</li></ul><p><strong>闵可夫斯基距离</strong> Minkowski distance<br><a target="_blank" rel="noopener" href="http://www.harumonia.top/image/NzaH"><img src="http://www.harumonia.top/images/2019/08/17/image4bfd8ac1d8b3156f.png" alt="image4bfd8ac1d8b3156f.png" loading="lazy"></a></p><ul><li>r=1,城市街区(也称曼哈顿,出租车,L1 范数)距离</li><li>r=2,欧几里得距离</li><li>r=♾,上确界距离</li></ul><p>度量与非度量</p><h4 id="数据对象之间的相似度-Similarities-between-Data-Objects"><a href="#数据对象之间的相似度-Similarities-between-Data-Objects" class="headerlink" title="数据对象之间的相似度 Similarities between Data Objects"></a>数据对象之间的相似度 Similarities between Data Objects</h4><h4 id="邻近性度量的例子-Examples-of-Proximity-Measures"><a href="#邻近性度量的例子-Examples-of-Proximity-Measures" class="headerlink" title="邻近性度量的例子 Examples of Proximity Measures"></a>邻近性度量的例子 Examples of Proximity Measures</h4><h5 id="二元数据的相似性度量"><a href="#二元数据的相似性度量" class="headerlink" title="二元数据的相似性度量"></a>二元数据的相似性度量</h5><ul><li>简单匹配系数 simple matching coefficient (SMC)<br><a target="_blank" rel="noopener" href="http://www.harumonia.top/image/N2RF"><img src="http://www.harumonia.top/images/2019/08/17/imagec78fb1c028be231c.png" alt="imagec78fb1c028be231c.png" loading="lazy"></a></li></ul><p>SMC 可以在一个仅包含是非题的测验中来发现回答问题相似的学生</p><ul><li>Jaccard 系数 Jaccard Coefficient<br><a target="_blank" rel="noopener" href="http://www.harumonia.top/image/N4tT"><img src="http://www.harumonia.top/images/2019/08/17/image709b0bba0e810a01.png" alt="image709b0bba0e810a01.png" loading="lazy"></a><br>常常用来处理非对称的二元属性对象</li></ul><h5 id="余弦相似度-Cosine-Similarity"><a href="#余弦相似度-Cosine-Similarity" class="headerlink" title="余弦相似度 Cosine Similarity"></a>余弦相似度 Cosine Similarity</h5><p>常用来度量文档相似度<br><img src="http://www.harumonia.top/images/2019/08/17/imagee4c8afe3e4e60ecf.png" alt="imagee4c8afe3e4e60ecf.png" loading="lazy"><br><a target="_blank" rel="noopener" href="http://www.harumonia.top/image/NGnU"><img src="http://www.harumonia.top/images/2019/08/17/image950d41dec2581905.png" alt="image950d41dec2581905.png" loading="lazy"></a></p><h5 id="广义-Jaccard-系数-Extended-Jaccard-Coefficient-Tanimoto-Coefficient"><a href="#广义-Jaccard-系数-Extended-Jaccard-Coefficient-Tanimoto-Coefficient" class="headerlink" title="广义 Jaccard 系数 Extended Jaccard Coefficient (Tanimoto Coefficient)"></a>广义 Jaccard 系数 Extended Jaccard Coefficient (Tanimoto Coefficient)</h5><p><a target="_blank" rel="noopener" href="http://www.harumonia.top/image/Nacx"><img src="http://www.harumonia.top/images/2019/08/17/image8002f990119f2a64.png" alt="image8002f990119f2a64.png" loading="lazy"></a></p><h5 id="相关性-Correlation"><a href="#相关性-Correlation" class="headerlink" title="相关性 Correlation"></a>相关性 Correlation</h5><p>皮尔森相关 Pearson’s correlation<br>判定是否存在线性关系</p><p><a target="_blank" rel="noopener" href="http://www.harumonia.top/image/NhsL"><img src="http://www.harumonia.top/images/2019/08/17/imagefa2b122d3c3982db.png" alt="imagefa2b122d3c3982db.png" loading="lazy"></a></p><p>Bregman 散度<br>Bregman 散度是损失或失真函数.损失函数的目的是度量用 x 近似 y 导致的失真或损失.<br>x 和 y 越类似,失真或损失就越小,因而 Bregman 散度可以用作相异性函数</p><h4 id="邻近度计算问题"><a href="#邻近度计算问题" class="headerlink" title="邻近度计算问题"></a>邻近度计算问题</h4><ol><li>当属性具有不同的尺度(scale)或相关时如何处理</li><li>当对象包含不同类型的属性(例如,定量属性和定性属性)是如何计算对象之间的邻近度</li><li>当属性具有不同的权重(即并非所有的属性都对对象的邻近度具有相等的贡献)时,如何处理邻近度计算</li></ol><h5 id="距离度量的标准化和相关性"><a href="#距离度量的标准化和相关性" class="headerlink" title="距离度量的标准化和相关性"></a>距离度量的标准化和相关性</h5><h1 id="wander-season"><a href="#wander-season" class="headerlink" title="wander season"></a>wander season</h1><h2 id="kaggle"><a href="#kaggle" class="headerlink" title="kaggle"></a>kaggle</h2><ul><li>The number of columns in the DataFrame is not equal to the number of features. One of the columns - ‘party’ is the target variable.</li></ul></div><div id="reward-container"><span class="hty-icon-button button-glow" id="reward-button" title="打赏" onclick="var qr = document.getElementById(&quot;qr&quot;); qr.style.display = (qr.style.display === &quot;none&quot;) ? &quot;block&quot; : &quot;none&quot;;"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-hand-coin-line"></use></svg></span><div id="reward-comment">I'm so cute. Please give me money.</div><div id="qr" style="display:none"><div style="display:inline-block"><a target="_blank" rel="noopener" href="https://harumona-blog.oss-cn-beijing.aliyuncs.com/blog/IMG_3741.JPG"><img loading="lazy" src="https://harumona-blog.oss-cn-beijing.aliyuncs.com/blog/IMG_3741.JPG" alt="支付宝" title="支付宝"></a><div><span style="color:#00a3ee"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-alipay-line"></use></svg></span></div></div><div style="display:inline-block"></div><div style="display:inline-block"><a target="_blank" rel="noopener" href="https://harumona-blog.oss-cn-beijing.aliyuncs.com/blog/IMG_3742.JPG"><img loading="lazy" src="https://harumona-blog.oss-cn-beijing.aliyuncs.com/blog/IMG_3742.JPG" alt="微信支付" title="微信支付"></a><div><span style="color:#2dc100"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-wechat-pay-line"></use></svg></span></div></div></div></div><ul class="post-copyright"><li class="post-copyright-author"><strong>本文作者：</strong>harumonia</li><li class="post-copyright-link"><strong>本文链接：</strong><a href="https://blog.harumonia.moe/2019-08-17-Introduction_to_data_mining-1/" title="Introduction to data mining(1)">https://blog.harumonia.moe/2019-08-17-Introduction_to_data_mining-1/</a></li><li class="post-copyright-license"><strong>版权声明：</strong>本博客所有文章除特别声明外，均默认采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" target="_blank" rel="noopener" title="CC BY-NC-SA 4.0 "><svg class="icon"><use xlink:href="#icon-creative-commons-line"></use></svg><svg class="icon"><use xlink:href="#icon-creative-commons-by-line"></use></svg><svg class="icon"><use xlink:href="#icon-creative-commons-nc-line"></use></svg><svg class="icon"><use xlink:href="#icon-creative-commons-sa-line"></use></svg></a>许可协议。</li></ul></section></article><div class="post-nav"><div class="post-nav-item"><a class="post-nav-prev" href="/2019-08-23-DA-intro-1/" rel="prev" title="数据分析拾遗(不定期补充)"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-arrow-left-s-line"></use></svg><span class="post-nav-text">数据分析拾遗(不定期补充)</span></a></div><div class="post-nav-item"><a class="post-nav-next" href="/2019-08-14-Be-a-better-pythonista-2/" rel="next" title="Be a better pythonista(2)"><span class="post-nav-text">Be a better pythonista(2)</span><svg class="icon" aria-hidden="true"><use xlink:href="#icon-arrow-right-s-line"></use></svg></a></div></div></div><div class="hty-card" id="comment"><div class="comment-tooltip text-center"><span>要不要和我说些什么？</span><br></div></div></main><footer class="sidebar-translate" id="footer"><div class="copyright"><span>&copy; 2018 – 2022 </span><span class="with-love" id="animate"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-cloud-line"></use></svg></span><span class="author">harumonia</span></div><div class="live_time"><span>本博客已萌萌哒地运行</span><span id="display_live_time"></span><span class="moe-text">(●'◡'●)</span><script>function blog_live_time() {
  setTimeout(blog_live_time, 1000);
  const start = new Date('2018-10-25T00:00:00');
  const now = new Date();
  const timeDiff = (now.getTime() - start.getTime());
  const msPerMinute = 60 * 1000;
  const msPerHour = 60 * msPerMinute;
  const msPerDay = 24 * msPerHour;
  const passDay = Math.floor(timeDiff / msPerDay);
  const passHour = Math.floor((timeDiff % msPerDay) / 60 / 60 / 1000);
  const passMinute = Math.floor((timeDiff % msPerHour) / 60 / 1000);
  const passSecond = Math.floor((timeDiff % msPerMinute) / 1000);
  display_live_time.innerHTML = " " + passDay + " 天 " + passHour + " 小时 " + passMinute + " 分 " + passSecond + " 秒";
}
blog_live_time();</script></div></footer><a class="hty-icon-button" id="back-to-top" aria-label="back-to-top" href="#"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-arrow-up-s-line"></use></svg><svg class="progress-circle-container" viewBox="0 0 100 100"><circle class="progress-circle" id="progressCircle" cx="50" cy="50" r="48" fill="none" stroke="#0078E7" stroke-width="2" stroke-linecap="round"></circle></svg></a><a class="popup-trigger hty-icon-button icon-search" id="search" target="_blank" rel="noopener" href="https://www.google.com/search?q=site:harumonia.moe" title="搜索"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-search-line"></use></svg></span></a></div></body></html>