<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><meta name="theme-color" content="#0078E7"><meta name="author" content="harumonia"><meta name="copyright" content="harumonia"><meta name="generator" content="Hexo 5.1.1"><meta name="theme" content="hexo-theme-yun"><title>sklearn构造性学习(1) | Zaxon</title><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@900&amp;display=swap" media="print" onload='this.media="all"'><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/star-markdown-css@0.1.25/dist/yun/yun-markdown.min.css"><script src="//at.alicdn.com/t/font_1140697_j5gk85dg4pf.js" async></script><script src="https://cdn.jsdelivr.net/npm/scrollreveal/dist/scrollreveal.min.js" defer></script><script>document.addEventListener("DOMContentLoaded", () => {
  [".post-card",".post-content img"].forEach((target)=> {
    ScrollReveal().reveal(target);
  })
});</script><link id="light-prism-css" rel="stylesheet" href="https://cdn.jsdelivr.net/npm/prismjs@latest/themes/prism.css" media="(prefers-color-scheme:light)"><link id="dark-prism-css" rel="stylesheet" href="https://cdn.jsdelivr.net/npm/prismjs@latest/themes/prism-tomorrow.css" media="(prefers-color-scheme:dark)"><link rel="icon" href="/yun.svg"><link rel="mask-icon" href="/yun.svg" color="#0078E7"><link rel="alternate icon" href="/yun.ico"><link rel="preload" href="/css/hexo-theme-yun.css" as="style"><link rel="preload" href="/js/utils.js" as="script"><link rel="preload" href="/js/hexo-theme-yun.js" as="script"><link rel="prefetch" href="/js/sidebar.js" as="script"><link rel="preconnect" href="https://cdn.jsdelivr.net" crossorigin><script id="yun-config">const Yun = window.Yun || {};
    window.CONFIG = {"hostname":"blog.harumonia.moe","root":"/","title":"Zaxon-迷雾中的藏宝地","version":"1.6.1","mode":"auto","copycode":true,"page":{"isPost":true},"i18n":{"placeholder":"搜索...","empty":"找不到您查询的内容: ${query}","hits":"找到 ${hits} 条结果","hits_time":"找到 ${hits} 条结果（用时 ${time} 毫秒）"},"anonymous_image":"https://cdn.jsdelivr.net/gh/YunYouJun/cdn/img/avatar/none.jpg","say":{"api":"https://v1.hitokoto.cn","hitokoto":true},"fireworks":{"colors":["102, 167, 221","62, 131, 225","33, 78, 194"]}};</script><link rel="stylesheet" href="/css/hexo-theme-yun.css"><script src="/js/utils.js"></script><script src="/js/hexo-theme-yun.js"></script><link rel="preconnect" href="https://www.google-analytics.com" crossorigin><script async src="https://www.googletagmanager.com/gtag/js?id=G-EBNGE3F0F6"></script><script>function gtag(){dataLayer.push(arguments)}CONFIG.hostname===location.hostname&&(window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-EBNGE3F0F6"))</script><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0];t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}()</script><meta name="description" content="构造性学习中，以理论为主，并结合一定的例子 本篇是机器学习的入门篇，主体的脉络差不多近似于 《数据挖掘导论》 一书"><meta property="og:type" content="article"><meta property="og:title" content="sklearn构造性学习(1)"><meta property="og:url" content="https://blog.harumonia.moe/2019-08-02-learning-sklearn-via-theory-1/index.html"><meta property="og:site_name" content="Zaxon"><meta property="og:description" content="构造性学习中，以理论为主，并结合一定的例子 本篇是机器学习的入门篇，主体的脉络差不多近似于 《数据挖掘导论》 一书"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://harumona-blog.oss-cn-beijing.aliyuncs.com/old_articles/4253159243.png?Expires=1602314295"><meta property="og:image" content="https://harumona-blog.oss-cn-beijing.aliyuncs.com/old_articles/2299684497.png?Expires=1602314397"><meta property="article:published_time" content="2019-08-02T08:41:00.000Z"><meta property="article:modified_time" content="2019-08-05T18:59:29.000Z"><meta property="article:author" content="harumonia"><meta property="article:tag" content="sklearn"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://harumona-blog.oss-cn-beijing.aliyuncs.com/old_articles/4253159243.png?Expires=1602314295"><script src="/js/ui/mode.js"></script></head><body><script defer src="https://cdn.jsdelivr.net/npm/animejs@latest"></script><script defer src="/js/ui/fireworks.js"></script><canvas class="fireworks"></canvas><div class="container"><a class="sidebar-toggle hty-icon-button" id="menu-btn"><div class="hamburger hamburger--spin" type="button"><span class="hamburger-box"><span class="hamburger-inner"></span></span></div></a><div class="sidebar-toggle sidebar-overlay"></div><aside class="sidebar"><script src="/js/sidebar.js"></script><ul class="sidebar-nav"><li class="sidebar-nav-item sidebar-nav-toc hty-icon-button sidebar-nav-active" data-target="post-toc-wrap" title="文章目录"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-list-ordered"></use></svg></li><li class="sidebar-nav-item sidebar-nav-overview hty-icon-button" data-target="site-overview-wrap" title="站点概览"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-passport-line"></use></svg></li></ul><div class="sidebar-panel" id="site-overview-wrap"><div class="site-info fix-top"><a class="site-author-avatar" href="/about/" title="harumonia"><img width="96" loading="lazy" src="https://harumona-blog.oss-cn-beijing.aliyuncs.com/blog/Ocabe.webp" alt="harumonia"></a><div class="site-author-name"><a href="/about/">harumonia</a></div><span class="site-name">Zaxon</span><sub class="site-subtitle">Find the key of soul</sub><div class="site-desciption">lazy</div></div><nav class="site-state"><a class="site-state-item hty-icon-button icon-home" href="/" title="首页"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-home-4-line"></use></svg></span></a><div class="site-state-item"><a href="/archives/" title="归档"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-archive-line"></use></svg></span><span class="site-state-item-count">130</span></a></div><div class="site-state-item"><a href="/categories/" title="分类"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-folder-2-line"></use></svg></span><span class="site-state-item-count">16</span></a></div><div class="site-state-item"><a href="/tags/" title="标签"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-price-tag-3-line"></use></svg></span><span class="site-state-item-count">71</span></a></div><a class="site-state-item hty-icon-button" href="/books" title="读书"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-book-2-line"></use></svg></span></a></nav><hr style="margin-bottom:.5rem"><div class="links-of-author"><a class="links-of-author-item hty-icon-button" rel="noopener" href="/atom.xml" title="RSS" target="_blank" style="color:orange"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-rss-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://qm.qq.com/cgi-bin/qm/qr?k=DSmoEtSKHITcV9pghYqqmSQ80-SPnPjm&amp;noverify=0" title="QQ" target="_blank" style="color:#12b7f5"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-qq-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://github.com/zxjlm" title="GitHub" target="_blank" style="color:#6e5494"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-github-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://www.douban.com/people/Zxj_Butterfly_m/" title="豆瓣" target="_blank" style="color:#072"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-douban-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://music.163.com/#/user/home?id=305617499" title="网易云音乐" target="_blank" style="color:#c20c0c"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-netease-cloud-music-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://space.bilibili.com/1801214" title="哔哩哔哩" target="_blank" style="color:#ff8eb3"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-bilibili-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="https://twitter.com/Harumonia1996" title="Twitter" target="_blank" style="color:#1da1f2"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-twitter-line"></use></svg></a><a class="links-of-author-item hty-icon-button" rel="noopener" href="mailto:zxjlm233@gmail.com" title="E-Mail" target="_blank" style="color:#8e71c1"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-mail-line"></use></svg></a></div><hr style="margin:.5rem 1rem"><div class="links"><a class="links-item hty-icon-button" href="/links/" title="我的小伙伴们" style="color:#1e90ff"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-genderless-line"></use></svg></a></div><br><a class="links-item hty-icon-button" id="toggle-mode-btn" href="javascript:;" title="Mode" style="color:#f1cb64"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-contrast-2-line"></use></svg></a></div><div class="sidebar-panel sidebar-panel-active" id="post-toc-wrap"><div class="post-toc"><div class="post-toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#K-%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95"><span class="toc-number">1.</span> <span class="toc-text">K 近邻算法</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%A1%E7%AE%97%E8%B7%9D%E7%A6%BB"><span class="toc-number">1.1.</span> <span class="toc-text">计算距离</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%AC%A7%E6%8B%89%E8%B7%9D%E7%A6%BB"><span class="toc-number">1.1.1.</span> <span class="toc-text">欧拉距离</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9B%BC%E5%93%88%E9%A1%BF%E8%B7%9D%E7%A6%BB"><span class="toc-number">1.1.2.</span> <span class="toc-text">曼哈顿距离</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%BB%E7%BB%93-%E9%97%B5%E5%8F%AF%E5%A4%AB%E6%96%AF%E5%9F%BA%E8%B7%9D%E7%A6%BB"><span class="toc-number">1.1.3.</span> <span class="toc-text">总结:闵可夫斯基距离</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%87%86%E7%A1%AE%E5%BA%A6"><span class="toc-number">1.2.</span> <span class="toc-text">准确度</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%B6%85%E5%8F%82%E6%95%B0"><span class="toc-number">1.3.</span> <span class="toc-text">超参数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8A%80%E6%9C%AF%E5%AE%9E%E7%8E%B0"><span class="toc-number">1.4.</span> <span class="toc-text">技术实现</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%BD%92%E4%B8%80%E5%8C%96"><span class="toc-number">1.5.</span> <span class="toc-text">数据归一化</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%94%B9%E8%BF%9B"><span class="toc-number">1.5.1.</span> <span class="toc-text">改进</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E5%AF%B9%E6%B5%8B%E8%AF%95%E6%95%B0%E6%8D%AE%E9%9B%86%E8%BF%9B%E8%A1%8C%E5%BD%92%E4%B8%80%E5%8C%96"><span class="toc-number">1.5.2.</span> <span class="toc-text">如何对测试数据集进行归一化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9E%E7%8E%B0"><span class="toc-number">1.5.3.</span> <span class="toc-text">实现</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BC%BA%E7%82%B9"><span class="toc-number">1.6.</span> <span class="toc-text">缺点</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AF%84%E4%BB%B7"><span class="toc-number">1.7.</span> <span class="toc-text">评价</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%AE%97%E6%B3%95"><span class="toc-number">2.</span> <span class="toc-text">线性回归算法</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%90%91%E9%87%8F%E5%8C%96"><span class="toc-number">2.1.</span> <span class="toc-text">向量化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AF%84%E4%BB%B7-1"><span class="toc-number">2.2.</span> <span class="toc-text">评价</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%9A%E5%85%83%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92"><span class="toc-number">2.3.</span> <span class="toc-text">多元线性回归</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9E%E7%8E%B0-1"><span class="toc-number">2.3.1.</span> <span class="toc-text">实现</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95"><span class="toc-number">3.</span> <span class="toc-text">梯度下降法</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B7%B1%E5%85%A5"><span class="toc-number">3.1.</span> <span class="toc-text">深入</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E4%B8%AD%E4%BD%BF%E7%94%A8%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95"><span class="toc-number">3.2.</span> <span class="toc-text">线性回归中使用梯度下降法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E7%9A%84%E5%90%91%E9%87%8F%E5%8C%96%E5%92%8C%E6%A0%87%E5%87%86%E5%8C%96"><span class="toc-number">3.3.</span> <span class="toc-text">梯度下降的向量化和标准化</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%9A%8F%E6%9C%BA%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95"><span class="toc-number">3.4.</span> <span class="toc-text">随机梯度下降法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#scikit-%E5%AE%9E%E7%8E%B0"><span class="toc-number">3.5.</span> <span class="toc-text">scikit 实现</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90-PCA"><span class="toc-number">4.</span> <span class="toc-text">主成分分析 PCA</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A2%AF%E5%BA%A6%E4%B8%8A%E5%8D%87%E6%B3%95%E8%A7%A3%E5%86%B3%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90%E9%97%AE%E9%A2%98"><span class="toc-number">4.1.</span> <span class="toc-text">梯度上升法解决主成分分析问题</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9E%E7%8E%B0-2"><span class="toc-number">4.2.</span> <span class="toc-text">实现</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%AB%98%E7%BB%B4%E6%95%B0%E6%8D%AE%E6%98%A0%E5%B0%84%E4%B8%BA%E4%BD%8E%E7%BB%B4"><span class="toc-number">4.3.</span> <span class="toc-text">高维数据映射为低维</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#scikit-%E5%AE%9E%E7%8E%B0-1"><span class="toc-number">4.4.</span> <span class="toc-text">scikit 实现</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%A4%9A%E9%A1%B9%E5%BC%8F%E5%9B%9E%E5%BD%92"><span class="toc-number">5.</span> <span class="toc-text">多项式回归</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BF%87%E6%8B%9F%E5%90%88%E5%92%8C%E6%AC%A0%E6%8B%9F%E5%90%88"><span class="toc-number">5.1.</span> <span class="toc-text">过拟合和欠拟合</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%B3%9B%E5%8C%96%E8%83%BD%E5%8A%9B"><span class="toc-number">5.1.1.</span> <span class="toc-text">模型的泛化能力</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AD%A6%E4%B9%A0%E6%9B%B2%E7%BA%BF"><span class="toc-number">5.2.</span> <span class="toc-text">学习曲线</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81"><span class="toc-number">5.2.1.</span> <span class="toc-text">交叉验证</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BD%91%E6%A0%BC%E6%90%9C%E7%B4%A2"><span class="toc-number">5.2.2.</span> <span class="toc-text">网格搜索</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%95%99%E4%B8%80%E6%B3%95-LOO-CV"><span class="toc-number">5.2.3.</span> <span class="toc-text">留一法 LOO-CV</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%81%8F%E5%B7%AE%E6%96%B9%E5%B7%AE%E6%9D%83%E8%A1%A1-bias-variance"><span class="toc-number">5.2.4.</span> <span class="toc-text">偏差方差权衡 bias variance</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%81%8F%E5%B7%AE-bias"><span class="toc-number">5.2.4.1.</span> <span class="toc-text">偏差(bias)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%96%B9%E5%B7%AE-variance"><span class="toc-number">5.2.4.2.</span> <span class="toc-text">方差(variance)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">5.2.4.3.</span> <span class="toc-text">总结</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E6%AD%A3%E5%88%99%E5%8C%96"><span class="toc-number">5.2.5.</span> <span class="toc-text">模型正则化</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#logistic-regression"><span class="toc-number">6.</span> <span class="toc-text">logistic regression</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%A7%A3%E5%86%B3%E5%A4%9A%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98"><span class="toc-number">6.1.</span> <span class="toc-text">解决多分类问题</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#OvR-One-vs-Rest"><span class="toc-number">6.1.1.</span> <span class="toc-text">OvR(One vs Rest)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#OvO-one-vs-one"><span class="toc-number">6.1.2.</span> <span class="toc-text">OvO(one vs one)</span></a></li></ol></li></ol></li></ol></div></div></div></aside><main class="sidebar-translate" id="content"><div id="post"><article class="hty-card post-block" itemscope itemtype="https://schema.org/Article"><link itemprop="mainEntityOfPage" href="https://blog.harumonia.moe/2019-08-02-learning-sklearn-via-theory-1/"><span hidden itemprop="author" itemscope itemtype="https://schema.org/Person"><meta itemprop="name" content="harumonia"><meta itemprop="description"></span><span hidden itemprop="publisher" itemscope itemtype="https://schema.org/Organization"><meta itemprop="name" content="Zaxon"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">sklearn构造性学习(1)</h1><div class="post-meta"><div class="post-time" style="display:inline-block"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-calendar-line"></use></svg></span><time title="创建时间：2019-08-02 08:41:00" itemprop="dateCreated datePublished" datetime="2019-08-02T08:41:00+00:00">2019-08-02</time><span class="post-meta-divider">-</span><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-calendar-2-line"></use></svg></span><time title="修改时间：2019-08-05 18:59:29" itemprop="dateModified" datetime="2019-08-05T18:59:29+00:00">2019-08-05</time></div><div class="post-classify"><span class="post-category"><span class="post-meta-item-icon" style="margin-right:3px"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-folder-line"></use></svg></span><span itemprop="about" itemscope itemtype="https://schema.org/Thing"><a class="category-item" href="/categories/%E6%BA%90%E6%B5%81%E6%B8%85%E6%B3%89/" style="--text-color:var(--hty-text-color)" itemprop="url" rel="index"><span itemprop="text">源流清泉</span></a></span> > <span itemprop="about" itemscope itemtype="https://schema.org/Thing"><a class="category-item" href="/categories/%E6%BA%90%E6%B5%81%E6%B8%85%E6%B3%89/Python/" style="--text-color:var(--hty-text-color)" itemprop="url" rel="index"><span itemprop="text">Python</span></a></span></span><span class="post-tag"><span class="post-meta-divider">-</span><a class="tag-item" href="/tags/sklearn/" style="--text-color:var(--hty-text-color)"><span class="post-meta-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-price-tag-3-line"></use></svg></span><span class="tag-name">sklearn</span></a></span></div><div class="post-author"><span class="author-name">harumonia</span></div></div></header><section class="post-body" itemprop="articleBody"><div class="post-content markdown-body" style="--smc-primary:#0078E7"><p>构造性学习中，以理论为主，并结合一定的例子</p><p>本篇是机器学习的入门篇，主体的脉络差不多近似于 《数据挖掘导论》 一书</p><a id="more"></a><h1 id="K-近邻算法"><a href="#K-近邻算法" class="headerlink" title="K 近邻算法"></a>K 近邻算法</h1><p><a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier">主要函数说明</a><br>k 近邻算法是非常特殊的,可以认为是没有模型,或者说训练集本身就是模型<br>寻找 k 个近邻,来判断 x 点<br>主要解决分类问题</p><h2 id="计算距离"><a href="#计算距离" class="headerlink" title="计算距离"></a>计算距离</h2><h3 id="欧拉距离"><a href="#欧拉距离" class="headerlink" title="欧拉距离"></a>欧拉距离</h3><p>$$<br>\sqrt{\sum_{i=1}^{n}\left(X_{i}^{(a)}-X_{i}^{(b)}\right)^{2}}<br>$$</p><h3 id="曼哈顿距离"><a href="#曼哈顿距离" class="headerlink" title="曼哈顿距离"></a>曼哈顿距离</h3><p><img src="https://harumona-blog.oss-cn-beijing.aliyuncs.com/old_articles/4253159243.png?Expires=1602314295" alt="p1" loading="lazy"><br>绿线:欧拉距离</p><h3 id="总结-闵可夫斯基距离"><a href="#总结-闵可夫斯基距离" class="headerlink" title="总结:闵可夫斯基距离"></a>总结:闵可夫斯基距离</h3><p>$$<br>\left(\sum_{i=1}^{n}\left|X_{i}^{(a)}-X_{i}^{(b)}\right|^{p}\right)^{\frac{1}{p}}<br>$$</p><h2 id="准确度"><a href="#准确度" class="headerlink" title="准确度"></a>准确度</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> accuracy_score

accuracy_score<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span>y_predict<span class="token punctuation">)</span>

<span class="token comment"># 或者直接从训练结果中导出准确度</span>
knn_clf<span class="token punctuation">.</span>score<span class="token punctuation">(</span>X_test<span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="超参数"><a href="#超参数" class="headerlink" title="超参数"></a>超参数</h2><p>超参数:在算法运行前需要决定的参数<br>模型参数:算法过程中学习的参数</p><p>KNN 算法没有模型参数<br>kNN 算法中的 k 是典型的超参数</p><p>如何寻找好的超参数:</p><pre><code>领域知识
经验数值
实验搜索</code></pre><blockquote><p>除了 k 之外还有一个重要的超参数</p></blockquote><p><strong>k 与各个投票点的距离</strong><br>好处:<br>使得模型更加科学<br>解决了平票的情况</p><p>使用方法:加入 <strong>weights</strong> 参数</p><p>由上述的闵可夫斯基距离,得到又一个超参数 <strong>p</strong>,用来判断使用的距离公式</p><h2 id="技术实现"><a href="#技术实现" class="headerlink" title="技术实现"></a>技术实现</h2><p>使用 np.sum 对 np 进行求和<br>使用列表推导式进行列表的遍历<br>使用 collection 的 Counter 的 Counter 类来计算”投票”的结果</p><h2 id="数据归一化"><a href="#数据归一化" class="headerlink" title="数据归一化"></a>数据归一化</h2><p>作用:将所有的数据都映射到同一个尺度中<br><strong>最值归一化</strong>:将所有的数据都映射到 0-1 之间<br>适用于分布有明显边界的情况(如像素 0-255,学生的考试分数 0-100)</p><h3 id="改进"><a href="#改进" class="headerlink" title="改进"></a>改进</h3><p><strong>均值方差归一化 standardization</strong>:把所有的数据归一到均值为 0,方差为 1 的分布中<br>适用于数据分布没有明显的边界;有可能存在极端数据值<br><em>一般情况下使用</em></p><p>$$<br>x_{\text {scale}}=\frac{x-x_{\text {mean}}}{s}<br>$$</p><h3 id="如何对测试数据集进行归一化"><a href="#如何对测试数据集进行归一化" class="headerlink" title="如何对测试数据集进行归一化"></a>如何对测试数据集进行归一化</h3><p>与训练集的归一化方法不同</p><pre class="line-numbers language-math" data-language="math"><code class="language-math">(x_test - mean\_train ) &#x2F; std\_train<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>原因:</p><ul><li>真实环境很可能无法得到测试数据的均值和方差(如只给你一个数据)</li><li>对数据的归一化也是算法的一部分</li></ul><p><img src="https://harumona-blog.oss-cn-beijing.aliyuncs.com/old_articles/2299684497.png?Expires=1602314397" alt="p2" loading="lazy"></p><h3 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> StandardScaler<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><h2 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h2><ul><li>效率低下</li><li>高度数据相关(对 outlier 更加敏感)</li><li>预测的结果不具有可解释性</li></ul><h2 id="评价"><a href="#评价" class="headerlink" title="评价"></a>评价</h2><p>secore() 进行准确率对比</p><h1 id="线性回归算法"><a href="#线性回归算法" class="headerlink" title="线性回归算法"></a>线性回归算法</h1><p>目标:找到 a 和 b,使</p><pre class="line-numbers language-math" data-language="math"><code class="language-math">\displaystyle\sum_&#123;i&#x3D;1&#125;^ny\raisebox&#123;0.2em&#125;&#123;(i)&#125; -ax\raisebox&#123;0.2em&#125;&#123;(i)&#125; +b<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>尽可能小<br>以上公式即 <strong>损失函数(lossfunction)</strong><br>部分函数中用上式计算拟合的程度,所以也称 <strong>效用函数(utility function)</strong><br>统称为 <strong>目标函数</strong></p><p>总结:</p><pre><code>通过分析问题,确定问题的损失函数或者效用函数
通过最优化损失函数或效用函数,获得机器学习的模型</code></pre><h2 id="向量化"><a href="#向量化" class="headerlink" title="向量化"></a>向量化</h2><p>一般情况下,向量化相较于普通法快很多</p><h2 id="评价-1"><a href="#评价-1" class="headerlink" title="评价"></a>评价</h2><p>均方误差 MSE<br>改进:<br>均方根误差 RMSE 使其对量纲更加敏感<br><em>上下的误差为均方根误差</em><br><strong>sklearn 中没有包装 RMSE</strong><br>平均绝对误差 MAE</p><p>$$<br>R M S E=\sqrt{\frac{1}{m} \sum_{i=1}^{m}\left(y_{t e s t}^{(i)}-\hat{y}_{t e s t}^{(i)}\right)^{2}}<br>$$</p><p>$$<br>M A E=\frac{1}{m} \sum_{i=1}^{m}\left|y_{t e s t}^{(i)}-\hat{y}_{t e s t}^{(i)}\right|<br>$$</p><h2 id="多元线性回归"><a href="#多元线性回归" class="headerlink" title="多元线性回归"></a>多元线性回归</h2><h3 id="实现-1"><a href="#实现-1" class="headerlink" title="实现"></a>实现</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>linear_model <span class="token keyword">import</span> LinearRegression

lin_reg <span class="token operator">=</span> LinearRegression<span class="token punctuation">(</span><span class="token punctuation">)</span>
lin_reg<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span>y_train<span class="token punctuation">)</span>
lin_reg<span class="token punctuation">.</span>coef_      <span class="token comment">#theta</span>
lin_reg<span class="token punctuation">.</span>intercept_    <span class="token comment">#截距</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="梯度下降法"><a href="#梯度下降法" class="headerlink" title="梯度下降法"></a>梯度下降法</h1><p>基于搜索的最优化方法<br>作用: 最小化一个损失函数<br>梯度上升法 : 最大化一个效用函数</p><h2 id="深入"><a href="#深入" class="headerlink" title="深入"></a>深入</h2><ul><li>批量梯度下降法</li><li>随机梯度下降法</li><li>小批量梯度下降法</li></ul><h2 id="线性回归中使用梯度下降法"><a href="#线性回归中使用梯度下降法" class="headerlink" title="线性回归中使用梯度下降法"></a>线性回归中使用梯度下降法</h2><p>在使用梯度下降法时,对目标函数要进行特殊的设计<br>虽然理论上挡土度非常大的时候,可以通过调节 eta 来得到想要的结果,但是会影响效率</p><h2 id="梯度下降的向量化和标准化"><a href="#梯度下降的向量化和标准化" class="headerlink" title="梯度下降的向量化和标准化"></a>梯度下降的向量化和标准化</h2><p>向量化:</p><pre><code>简化了公式</code></pre><p>标准化:</p><pre><code>在使用梯度下降法之前,将数据归一化</code></pre><p>梯度下降法相比标准方程在进行大数据处理时具有明显优势</p><h2 id="随机梯度下降法"><a href="#随机梯度下降法" class="headerlink" title="随机梯度下降法"></a>随机梯度下降法</h2><p>用精度换时间<br>学习率逐渐递减</p><h2 id="scikit-实现"><a href="#scikit-实现" class="headerlink" title="scikit 实现"></a>scikit 实现</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python">
<span class="token comment"># 使用波士顿房价数据集</span>
<span class="token keyword">from</span> sklearn <span class="token keyword">import</span> datasets

boston <span class="token operator">=</span> datasets<span class="token punctuation">.</span>load_boston<span class="token punctuation">(</span><span class="token punctuation">)</span>
X <span class="token operator">=</span> boston<span class="token punctuation">.</span>data
y <span class="token operator">=</span> boston<span class="token punctuation">.</span>target

X <span class="token operator">=</span> X<span class="token punctuation">[</span>y <span class="token operator">&lt;</span> <span class="token number">50.0</span><span class="token punctuation">]</span>
y <span class="token operator">=</span> y<span class="token punctuation">[</span>y <span class="token operator">&lt;</span> <span class="token number">50.0</span><span class="token punctuation">]</span>


<span class="token comment"># 模型分类</span>
<span class="token keyword">from</span> playML<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split

X_train<span class="token punctuation">,</span> X_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">,</span> seed<span class="token operator">=</span><span class="token number">666</span><span class="token punctuation">)</span>


<span class="token comment"># 归一化</span>
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> StandardScaler

standardScaler <span class="token operator">=</span> StandardScaler<span class="token punctuation">(</span><span class="token punctuation">)</span>
standardScaler<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">)</span>
X_train_standard <span class="token operator">=</span> standardScaler<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>X_train<span class="token punctuation">)</span>
X_test_standard <span class="token operator">=</span> standardScaler<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>X_test<span class="token punctuation">)</span>


<span class="token comment"># 正式使用scikit中的SDG</span>
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>linear_model <span class="token keyword">import</span> SGDRegressor

sgd_reg <span class="token operator">=</span> SGDRegressor<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token operator">%</span>time sgd_reg<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train_standard<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>
sgd_reg<span class="token punctuation">.</span>score<span class="token punctuation">(</span>X_test_standard<span class="token punctuation">,</span> y_test<span class="token punctuation">)</span>

sgd_reg <span class="token operator">=</span> SGDRegressor<span class="token punctuation">(</span>n_iter<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">)</span>
<span class="token operator">%</span>time sgd_reg<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train_standard<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>
sgd_reg<span class="token punctuation">.</span>score<span class="token punctuation">(</span>X_test_standard<span class="token punctuation">,</span> y_test<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h1 id="主成分分析-PCA"><a href="#主成分分析-PCA" class="headerlink" title="主成分分析 PCA"></a>主成分分析 PCA</h1><ul><li>一个非监督的机器学习算法</li><li>主要用于数据降维</li><li>通过降维,可以发现更便于人类理解的特征</li><li>其他应用:可视化;去噪</li></ul><blockquote><p>找到一个轴,所有的点映射到这个轴之后方差最大</p></blockquote><p>S1:将样例的均值归零(作用是化简公式)(<strong>demean</strong>)<br>S2:求轴的方向 w=(w1,w2),使得所有的样本,映射到 w 以后,!</p><p><strong>区分 PAC 和线性回归</strong></p><h2 id="梯度上升法解决主成分分析问题"><a href="#梯度上升法解决主成分分析问题" class="headerlink" title="梯度上升法解决主成分分析问题"></a>梯度上升法解决主成分分析问题</h2><p>注意:</p><ul><li>每次求一个单位方向</li><li>不能用 0 向量开始</li><li>不能使用 StandardScaler 标准化数据</li></ul><h2 id="实现-2"><a href="#实现-2" class="headerlink" title="实现"></a>实现</h2><p>S1:</p><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">demean</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> X <span class="token operator">-</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>X<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><h2 id="高维数据映射为低维"><a href="#高维数据映射为低维" class="headerlink" title="高维数据映射为低维"></a>高维数据映射为低维</h2><p>低维的数据是可以返回到高维的, <strong>但是存在缺损</strong></p><h2 id="scikit-实现-1"><a href="#scikit-实现-1" class="headerlink" title="scikit 实现"></a>scikit 实现</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python">pca <span class="token operator">=</span> PCA<span class="token punctuation">(</span><span class="token number">0.95</span><span class="token punctuation">)</span> <span class="token comment"># 锁定精度</span>
pca<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">)</span>

pca<span class="token punctuation">.</span>n_components_ <span class="token comment">#依据X_train确定保留的维度</span>

knn_clf <span class="token operator">=</span> KNeighborsClassifier<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 降维后进行分类</span>
knn_clf<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train_reduction<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>

knn_clf<span class="token punctuation">.</span>score<span class="token punctuation">(</span>X_test_reduction<span class="token punctuation">,</span> y_test<span class="token punctuation">)</span>

<span class="token comment"># 可视化</span>
pca <span class="token operator">=</span> PCA<span class="token punctuation">(</span>n_components<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
pca<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X<span class="token punctuation">)</span>
X_reduction <span class="token operator">=</span> pca<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>X<span class="token punctuation">)</span>

<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>X_reduction<span class="token punctuation">[</span>y<span class="token operator">==</span>i<span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> X_reduction<span class="token punctuation">[</span>y<span class="token operator">==</span>i<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> alpha<span class="token operator">=</span><span class="token number">0.8</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p><strong>PCA 在降维的过程中还有降噪的作用,降噪的结果就是,维度降低,但是准确率反而提升了</strong></p><h1 id="多项式回归"><a href="#多项式回归" class="headerlink" title="多项式回归"></a>多项式回归</h1><p>实际中,大多数的数据都是非线性的关系</p><ul><li><p>PolynomialFeatures(degeree=3)<br>生成三次多项式<br>个数为 10<br>一次 3 1,x1,x2<br>二次 3 x1^2,x2^2,x1*x2<br>三次 4 x1^3,x2^3,x1^2*x2,x1*x2^2</p></li><li><p>pipeline</p></li></ul><pre class="line-numbers language-python" data-language="python"><code class="language-python">x <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>uniform<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> size<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">)</span>
X <span class="token operator">=</span> x<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
y <span class="token operator">=</span> <span class="token number">0.5</span> <span class="token operator">*</span> x<span class="token operator">**</span><span class="token number">2</span> <span class="token operator">+</span> x <span class="token operator">+</span> <span class="token number">2</span> <span class="token operator">+</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span>

<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>pipeline <span class="token keyword">import</span> Pipeline
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> StandardScaler

poly_reg <span class="token operator">=</span> Pipeline<span class="token punctuation">(</span><span class="token punctuation">[</span>
    <span class="token punctuation">(</span><span class="token string">"poly"</span><span class="token punctuation">,</span> PolynomialFeatures<span class="token punctuation">(</span>degree<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">"std_scaler"</span><span class="token punctuation">,</span> StandardScaler<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">"lin_reg"</span><span class="token punctuation">,</span> LinearRegression<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>


poly_reg<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X<span class="token punctuation">,</span> y<span class="token punctuation">)</span>
y_predict <span class="token operator">=</span> poly_reg<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X<span class="token punctuation">)</span>


plt<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>np<span class="token punctuation">.</span>sort<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span> y_predict<span class="token punctuation">[</span>np<span class="token punctuation">.</span>argsort<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">'r'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h2 id="过拟合和欠拟合"><a href="#过拟合和欠拟合" class="headerlink" title="过拟合和欠拟合"></a>过拟合和欠拟合</h2><p>过拟合:训练测试集上表现很好,但在测试数据集上表现不好</p><h3 id="模型的泛化能力"><a href="#模型的泛化能力" class="headerlink" title="模型的泛化能力"></a>模型的泛化能力</h3><p>使用训练数据集和测试数据集</p><blockquote><p>测试数据集的意义就是评估模型的泛化能力</p></blockquote><h2 id="学习曲线"><a href="#学习曲线" class="headerlink" title="学习曲线"></a>学习曲线</h2><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">plot_learning_curve</span><span class="token punctuation">(</span>algo<span class="token punctuation">,</span> X_train<span class="token punctuation">,</span> X_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test<span class="token punctuation">)</span><span class="token punctuation">:</span>
    train_score <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    test_score <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>X_train<span class="token punctuation">)</span><span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        algo<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">[</span><span class="token punctuation">:</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> y_train<span class="token punctuation">[</span><span class="token punctuation">:</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>

        y_train_predict <span class="token operator">=</span> algo<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X_train<span class="token punctuation">[</span><span class="token punctuation">:</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>
        train_score<span class="token punctuation">.</span>append<span class="token punctuation">(</span>mean_squared_error<span class="token punctuation">(</span>y_train<span class="token punctuation">[</span><span class="token punctuation">:</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span> y_train_predict<span class="token punctuation">)</span><span class="token punctuation">)</span>

        y_test_predict <span class="token operator">=</span> algo<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X_test<span class="token punctuation">)</span>
        test_score<span class="token punctuation">.</span>append<span class="token punctuation">(</span>mean_squared_error<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span> y_test_predict<span class="token punctuation">)</span><span class="token punctuation">)</span>

    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token punctuation">[</span>i <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>X_train<span class="token punctuation">)</span><span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                               np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>train_score<span class="token punctuation">)</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">"train"</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token punctuation">[</span>i <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>X_train<span class="token punctuation">)</span><span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
                               np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>test_score<span class="token punctuation">)</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">"test"</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>axis<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>X_train<span class="token punctuation">)</span><span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

plot_learning_curve<span class="token punctuation">(</span>LinearRegression<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> X_train<span class="token punctuation">,</span> X_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><blockquote><p>注意,针对特定测试数据集的过拟合<br>增加 验证数据集(调整超参数使用的数据集)</p></blockquote><h3 id="交叉验证"><a href="#交叉验证" class="headerlink" title="交叉验证"></a>交叉验证</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> cross_val_score

knn_clf <span class="token operator">=</span> KNeighborsClassifier<span class="token punctuation">(</span><span class="token punctuation">)</span>
cross_val_score<span class="token punctuation">(</span>knn_clf<span class="token punctuation">,</span> X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>


best_k<span class="token punctuation">,</span> best_p<span class="token punctuation">,</span> best_score <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span>
<span class="token keyword">for</span> k <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span> p <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        knn_clf <span class="token operator">=</span> KNeighborsClassifier<span class="token punctuation">(</span>weights<span class="token operator">=</span><span class="token string">"distance"</span><span class="token punctuation">,</span> n_neighbors<span class="token operator">=</span>k<span class="token punctuation">,</span> p<span class="token operator">=</span>p<span class="token punctuation">)</span>
        scores <span class="token operator">=</span> cross_val_score<span class="token punctuation">(</span>knn_clf<span class="token punctuation">,</span> X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>
        score <span class="token operator">=</span> np<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>scores<span class="token punctuation">)</span>
        <span class="token keyword">if</span> score <span class="token operator">></span> best_score<span class="token punctuation">:</span>
            best_k<span class="token punctuation">,</span> best_p<span class="token punctuation">,</span> best_score <span class="token operator">=</span> k<span class="token punctuation">,</span> p<span class="token punctuation">,</span> score

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Best K ="</span><span class="token punctuation">,</span> best_k<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Best P ="</span><span class="token punctuation">,</span> best_p<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"Best Score ="</span><span class="token punctuation">,</span> best_score<span class="token punctuation">)</span>


best_knn_clf <span class="token operator">=</span> KNeighborsClassifier<span class="token punctuation">(</span>weights<span class="token operator">=</span><span class="token string">"distance"</span><span class="token punctuation">,</span> n_neighbors<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> p<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>
best_knn_clf<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span>
best_knn_clf<span class="token punctuation">.</span>score<span class="token punctuation">(</span>X_test<span class="token punctuation">,</span> y_test<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>将训练数据分为 k 份,训练 k 个模型,并进行交叉验证<br>最后求均值</p><h3 id="网格搜索"><a href="#网格搜索" class="headerlink" title="网格搜索"></a>网格搜索</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python">
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> GridSearchCV

param_grid <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token punctuation">&#123;</span>
        <span class="token string">'weights'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'distance'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token string">'n_neighbors'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>i <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">11</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token string">'p'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span>i <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
    <span class="token punctuation">&#125;</span>
<span class="token punctuation">]</span>

grid_search <span class="token operator">=</span> GridSearchCV<span class="token punctuation">(</span>knn_clf<span class="token punctuation">,</span> param_grid<span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
grid_search<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">,</span> y_train<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="留一法-LOO-CV"><a href="#留一法-LOO-CV" class="headerlink" title="留一法 LOO-CV"></a>留一法 LOO-CV</h3><p>把训练数据集分成 m 份,成为留一法</p><blockquote><p>Leabe-One_out Cross Validation</p></blockquote><p>优点:完全不受随机的印象,最接近模型真正的性能指标<br>缺点:计算量巨大</p><blockquote><p>论文中验证严谨性</p></blockquote><h3 id="偏差方差权衡-bias-variance"><a href="#偏差方差权衡-bias-variance" class="headerlink" title="偏差方差权衡 bias variance"></a>偏差方差权衡 bias variance</h3><p>模型误差 = 偏差+方差+不可避免的误差</p><h4 id="偏差-bias"><a href="#偏差-bias" class="headerlink" title="偏差(bias)"></a>偏差(bias)</h4><p>导致偏差的主要原因:<br>对问题本身的假设不正确<br>如:非线性数据使用线性回归</p><h4 id="方差-variance"><a href="#方差-variance" class="headerlink" title="方差(variance)"></a>方差(variance)</h4><p>数据的一点点扰动都会较大的影响模型<br>通常原因,使用的模型太复杂<br>如,高阶多项式回归</p><p><strong>机器学习的主要挑战来自于方差</strong></p><p>1.降低模型复杂度 2.减少数据维度;降噪 3.增加样本书 4.使用验证集</p><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>有一些算法天生是高方差算法. 如 KNN<br>非参数学习的通常都是高方差算法,因为不对数据进行人和假设</p><p>you 一些算法天生就是高偏差算法. 如线性回归<br>参数学习通常都是高偏差算法,因为对数据具有极强的假设</p><p>大多数算法具有相应的参数,可以调整偏差和方差<br>如 kNN 中的 k\线性回归中使用多项式回归</p><p>偏差和方差是矛盾的<br>降低偏差会提高方差,反之亦然.</p><h3 id="模型正则化"><a href="#模型正则化" class="headerlink" title="模型正则化"></a>模型正则化</h3><p>$$<br>J(\theta)=M S E(y, \hat{y} ; \theta)+\alpha \frac{1}{2} \sum_{i=1}^{n} \theta_{i}^{2}<br>$$</p><h1 id="logistic-regression"><a href="#logistic-regression" class="headerlink" title="logistic regression"></a>logistic regression</h1><h2 id="解决多分类问题"><a href="#解决多分类问题" class="headerlink" title="解决多分类问题"></a>解决多分类问题</h2><p>将多分类问题简化为二分类问题</p><h3 id="OvR-One-vs-Rest"><a href="#OvR-One-vs-Rest" class="headerlink" title="OvR(One vs Rest)"></a>OvR(One vs Rest)</h3><p>n 个类别进行 n 次分类,选择分类得分最高的</p><h3 id="OvO-one-vs-one"><a href="#OvO-one-vs-one" class="headerlink" title="OvO(one vs one)"></a>OvO(one vs one)</h3><p>n 个类别进行 C(n,2)次分类,选择赢数最高的分类</p><p><strong>ovo 耗时更长,准确率更高</strong></p></div><div id="reward-container"><span class="hty-icon-button button-glow" id="reward-button" title="打赏" onclick="var qr = document.getElementById(&quot;qr&quot;); qr.style.display = (qr.style.display === &quot;none&quot;) ? &quot;block&quot; : &quot;none&quot;;"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-hand-coin-line"></use></svg></span><div id="reward-comment">I'm so cute. Please give me money.</div><div id="qr" style="display:none"><div style="display:inline-block"><a target="_blank" rel="noopener" href="https://harumona-blog.oss-cn-beijing.aliyuncs.com/blog/IMG_3741.JPG"><img loading="lazy" src="https://harumona-blog.oss-cn-beijing.aliyuncs.com/blog/IMG_3741.JPG" alt="支付宝" title="支付宝"></a><div><span style="color:#00a3ee"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-alipay-line"></use></svg></span></div></div><div style="display:inline-block"></div><div style="display:inline-block"><a target="_blank" rel="noopener" href="https://harumona-blog.oss-cn-beijing.aliyuncs.com/blog/IMG_3742.JPG"><img loading="lazy" src="https://harumona-blog.oss-cn-beijing.aliyuncs.com/blog/IMG_3742.JPG" alt="微信支付" title="微信支付"></a><div><span style="color:#2dc100"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-wechat-pay-line"></use></svg></span></div></div></div></div><ul class="post-copyright"><li class="post-copyright-author"><strong>本文作者：</strong>harumonia</li><li class="post-copyright-link"><strong>本文链接：</strong><a href="https://blog.harumonia.moe/2019-08-02-learning-sklearn-via-theory-1/" title="sklearn构造性学习(1)">https://blog.harumonia.moe/2019-08-02-learning-sklearn-via-theory-1/</a></li><li class="post-copyright-license"><strong>版权声明：</strong>本博客所有文章除特别声明外，均默认采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" target="_blank" rel="noopener" title="CC BY-NC-SA 4.0 "><svg class="icon"><use xlink:href="#icon-creative-commons-line"></use></svg><svg class="icon"><use xlink:href="#icon-creative-commons-by-line"></use></svg><svg class="icon"><use xlink:href="#icon-creative-commons-nc-line"></use></svg><svg class="icon"><use xlink:href="#icon-creative-commons-sa-line"></use></svg></a>许可协议。</li></ul></section></article><div class="post-nav"><div class="post-nav-item"><a class="post-nav-prev" href="/2019-08-04-learning-sklearn-via-practice-1/" rel="prev" title="sklearn应用性学习(1)"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-arrow-left-s-line"></use></svg><span class="post-nav-text">sklearn应用性学习(1)</span></a></div><div class="post-nav-item"><a class="post-nav-next" href="/2019-07-30-questions-and-solutions-of-flask-deploy-2/" rel="next" title="flask部署(2)"><span class="post-nav-text">flask部署(2)</span><svg class="icon" aria-hidden="true"><use xlink:href="#icon-arrow-right-s-line"></use></svg></a></div></div></div><div class="hty-card" id="comment"><div class="comment-tooltip text-center"><span>要不要和我说些什么？</span><br></div></div></main><footer class="sidebar-translate" id="footer"><div class="copyright"><span>&copy; 2018 – 2022 </span><span class="with-love" id="animate"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-cloud-line"></use></svg></span><span class="author">harumonia</span></div><div class="live_time"><span>本博客已萌萌哒地运行</span><span id="display_live_time"></span><span class="moe-text">(●'◡'●)</span><script>function blog_live_time() {
  setTimeout(blog_live_time, 1000);
  const start = new Date('2018-10-25T00:00:00');
  const now = new Date();
  const timeDiff = (now.getTime() - start.getTime());
  const msPerMinute = 60 * 1000;
  const msPerHour = 60 * msPerMinute;
  const msPerDay = 24 * msPerHour;
  const passDay = Math.floor(timeDiff / msPerDay);
  const passHour = Math.floor((timeDiff % msPerDay) / 60 / 60 / 1000);
  const passMinute = Math.floor((timeDiff % msPerHour) / 60 / 1000);
  const passSecond = Math.floor((timeDiff % msPerMinute) / 1000);
  display_live_time.innerHTML = " " + passDay + " 天 " + passHour + " 小时 " + passMinute + " 分 " + passSecond + " 秒";
}
blog_live_time();</script></div></footer><a class="hty-icon-button" id="back-to-top" aria-label="back-to-top" href="#"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-arrow-up-s-line"></use></svg><svg class="progress-circle-container" viewBox="0 0 100 100"><circle class="progress-circle" id="progressCircle" cx="50" cy="50" r="48" fill="none" stroke="#0078E7" stroke-width="2" stroke-linecap="round"></circle></svg></a><a class="popup-trigger hty-icon-button icon-search" id="search" target="_blank" rel="noopener" href="https://www.google.com/search?q=site:harumonia.moe" title="搜索"><span class="site-state-item-icon"><svg class="icon" aria-hidden="true"><use xlink:href="#icon-search-line"></use></svg></span></a></div></body></html>