<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 5.1.1"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.ico"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.ico"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css"><link rel="stylesheet" href="https://cdn.bootcdn.net/ajax/libs/pace/1.0.2/themes/silver/pace-theme-center-atom.min.css"><script src="//cdn.bootcdn.net/ajax/libs/pace/1.0.2/pace.min.js"></script><script id="hexo-configurations">var NexT=window.NexT||{},CONFIG={hostname:"blog.harumonia.moe",root:"/",scheme:"Gemini",version:"7.8.0",exturl:!1,sidebar:{position:"left",display:"post",padding:18,offset:12,onmobile:!1},copycode:{enable:!0,show_result:!0,style:"mac"},back2top:{enable:!0,sidebar:!0,scrollpercent:!0},bookmark:{enable:!1,color:"#222",save:"auto"},fancybox:!1,mediumzoom:!0,lazyload:!0,pangu:!1,comments:{style:"tabs",active:null,storage:!0,lazyload:!1,nav:null},algolia:{hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}},localsearch:{enable:!0,trigger:"auto",top_n_per_article:1,unescape:!1,preload:!1},motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},path:"search.xml"}</script><meta name="description" content="提高爬虫效率主要从三个方面开始复习。  并发 ip cookies  并发必然引发的一个结果就是反爬虫机制，这种时候爬虫的效率不会因为并发而提高，反而会因为网站的防御机制拖累爬虫的速度。 自然而然地就引出了 2，代理爬虫。代理爬虫能够从多个 ip 发送请求，减小了单个 ip 的请求频率，自然触发反爬虫机制的概率也就小了很多。 但是新的问题又出现了，对于需要 登录 的网站，需要提交 cookies"><meta property="og:type" content="article"><meta property="og:title" content="python爬虫复习(2) 提高效率"><meta property="og:url" content="https://blog.harumonia.moe/2020-01-08-spider-review-2-Improve-efficiency/index.html"><meta property="og:site_name" content="Zaxon"><meta property="og:description" content="提高爬虫效率主要从三个方面开始复习。  并发 ip cookies  并发必然引发的一个结果就是反爬虫机制，这种时候爬虫的效率不会因为并发而提高，反而会因为网站的防御机制拖累爬虫的速度。 自然而然地就引出了 2，代理爬虫。代理爬虫能够从多个 ip 发送请求，减小了单个 ip 的请求频率，自然触发反爬虫机制的概率也就小了很多。 但是新的问题又出现了，对于需要 登录 的网站，需要提交 cookies"><meta property="og:locale" content="zh_CN"><meta property="article:published_time" content="2020-01-08T20:02:00.000Z"><meta property="article:modified_time" content="2020-01-08T20:05:06.000Z"><meta property="article:author" content="harumonia"><meta property="article:tag" content="spider"><meta property="article:tag" content="协程"><meta name="twitter:card" content="summary"><link rel="canonical" href="https://blog.harumonia.moe/2020-01-08-spider-review-2-Improve-efficiency/"><script id="page-configurations">CONFIG.page={sidebar:"",isHome:!1,isPost:!0,lang:"zh-CN"}</script><title>python爬虫复习(2) 提高效率 | Zaxon</title><noscript><style>.sidebar-inner,.use-motion .brand,.use-motion .collection-header,.use-motion .comments,.use-motion .menu-item,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line-before i{left:initial}.use-motion .logo-line-after i{right:initial}</style></noscript><script>fetch("https://v1.hitokoto.cn/?c=i").then(function(t){return t.json()}).then(function(t){var o=document.getElementById("hitokoto"),n=document.getElementById("hitofrom");o.innerHTML=t.hitokoto,n.innerHTML="--- "+t.from}).catch(function(t){console.error(t)})</script></head><body itemscope itemtype="http://schema.org/WebPage"><div class="container use-motion"><div class="headband"></div><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏"><span class="toggle-line toggle-line-first"></span> <span class="toggle-line toggle-line-middle"></span> <span class="toggle-line toggle-line-last"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span><h1 class="site-title">Zaxon</h1><span class="logo-line-after"><i></i></span></a><p class="site-subtitle" itemprop="description">Find the key of soul</p><p class="site-hit" id="hitokoto"></p><p class="site-hit" id="hitofrom"></p></div><div class="site-nav-right"><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-fw fa-fab fa-home"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-fw fa-fab fa-user"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-fw fa-fab fa-tags"></i>标签<span class="badge">56</span></a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-fw fa-fab fa-th"></i>分类<span class="badge">18</span></a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-fw fa-fab fa-archive"></i>归档<span class="badge">106</span></a></li><li class="menu-item menu-item-book"><a href="/books/" rel="section"><i class="fa fa-fw fa-fab fa-book"></i>图书</a></li><li class="menu-item menu-item-movie"><a href="/movies/" rel="section"><i class="fa fa-fw fa-fab fa-film"></i>电影</a></li><li class="menu-item menu-item-game"><a href="/games/" rel="section"><i class="fa fa-fw fa-fab fa-gamepad"></i>游戏</a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索</a></li></ul></nav><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"><input autocomplete="off" autocapitalize="off" placeholder="搜索..." spellcheck="false" type="search" class="search-input"></div><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span></div><div id="search-result"><div id="no-result"><i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i></div></div></div></div></div></header><div class="reading-progress-bar"></div><a href="https://github.com/zxjlm" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin:130px 106px" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><main class="main"><div class="main-inner"><div class="content-wrap"><div class="content post posts-expand"><article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://blog.harumonia.moe/2020-01-08-spider-review-2-Improve-efficiency/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="https://harumona-blog.oss-cn-beijing.aliyuncs.com/blog/Ocabe.webp"><meta itemprop="name" content="harumonia"><meta itemprop="description" content="lazy"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Zaxon"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">python爬虫复习(2) 提高效率</h1><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2020-01-08 20:02:00 / 修改时间：20:05:06" itemprop="dateCreated datePublished" datetime="2020-01-08T20:02:00+00:00">2020-01-08</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-folder-o"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%E6%BA%90%E6%B5%81%E6%B8%85%E6%B3%89/" itemprop="url" rel="index"><span itemprop="name">源流清泉</span></a> </span>， <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/%E6%BA%90%E6%B5%81%E6%B8%85%E6%B3%89/Python/" itemprop="url" rel="index"><span itemprop="name">Python</span></a> </span></span><span id="/2020-01-08-spider-review-2-Improve-efficiency/" class="post-meta-item leancloud_visitors" data-flag-title="python爬虫复习(2) 提高效率" title="阅读次数"><span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="post-meta-item-text">阅读次数：</span> <span class="leancloud-visitors-count"></span> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-comment-o"></i> </span><span class="post-meta-item-text">Valine：</span> <a title="valine" href="/2020-01-08-spider-review-2-Improve-efficiency/#valine-comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/2020-01-08-spider-review-2-Improve-efficiency/" itemprop="commentCount"></span></a></span><br><span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="fa fa-file-word-o"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>8.4k</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="fa fa-clock-o"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>26 分钟</span></span></div></header><div class="post-body" itemprop="articleBody"><p>提高爬虫效率主要从三个方面开始复习。</p><ol><li>并发</li><li>ip</li><li>cookies</li></ol><p>并发必然引发的一个结果就是反爬虫机制，这种时候爬虫的效率不会因为并发而提高，反而会因为网站的防御机制拖累爬虫的速度。</p><p>自然而然地就引出了 2，代理爬虫。代理爬虫能够从多个 ip 发送请求，减小了单个 ip 的请求频率，自然触发反爬虫机制的概率也就小了很多。</p><p>但是新的问题又出现了，对于需要 <strong>登录</strong> 的网站，需要提交 cookies 来模拟登录情况，模拟登录不难，但是同一个 cookies 从不同的 ip 同时发送请求很明显不合常理，依然会触发反爬虫机制。</p><p>这是到目前为止我所遇到的影响爬虫效率的问题，就在这里做一个总结吧，如果后续遇到新的效率相关的问题，再做补充。</p><a id="more"></a><h1 id="并发"><a href="#并发" class="headerlink" title="并发"></a>并发</h1><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在 2019 年，我阅读了 python cookbook，其中对这一方面有较为详细且透彻的讲述，比较适合有 python 基础的人学习。<br>多进程、多线程是 python 程序员的必修课之一。因为，即使脱离了爬虫，机器学习、web 开发等方面，多线程、多进程依旧有着举足轻重的地位。<br>这是开发者的一个小分水岭，它在一定程度上决定了程序效率的高低。</p><h2 id="python-中的多进程方法"><a href="#python-中的多进程方法" class="headerlink" title="python 中的多进程方法"></a>python 中的多进程方法</h2><h3 id="多线程、多进程、协程爬虫"><a href="#多线程、多进程、协程爬虫" class="headerlink" title="多线程、多进程、协程爬虫"></a>多线程、多进程、协程爬虫</h3><p>对于操作系统来说，一个任务就是一个进程（Process），比如打开一个浏览器就是启动一个浏览器进程，打开一个记事本就启动了一个记事本进程，打开两个记事本就启动了两个记事本进程，打开一个 Word 就启动了一个 Word 进程。</p><p>有些进程还不止同时干一件事，比如 Word，它可以同时进行打字、拼写检查、打印等事情。在一个进程内部，要同时干多件事，就需要同时运行多个“子任务”，我们把进程内的这些“子任务”称为线程（Thread）。</p><h3 id="进程、线程、协程的区别"><a href="#进程、线程、协程的区别" class="headerlink" title="进程、线程、协程的区别"></a>进程、线程、协程的区别</h3><p>多进程模式最大的优点就是稳定性高，因为一个子进程崩溃了，不会影响主进程和其他子进程。（当然主进程挂了所有进程就全挂了，但是 Master 进程只负责分配任务，挂掉的概率低）著名的 Apache 最早就是采用多进程模式。</p><p>多进程模式的缺点是创建进程的代价大，在 Unix/Linux 系统下，用 fork 调用还行，在 Windows 下创建进程开销巨大。另外，操作系统能同时运行的进程数也是有限的，在内存和 CPU 的限制下，如果有几千个进程同时运行，操作系统连调度都会成问题。</p><p>多线程模式通常比多进程快一点，但是也快不到哪去，而且，多线程模式致命的缺点就是任何一个线程挂掉都可能直接造成整个进程崩溃，因为所有线程共享进程的内存。</p><h4 id="协程的优势："><a href="#协程的优势：" class="headerlink" title="协程的优势："></a>协程的优势：</h4><p>最大的优势就是协程 <strong>极高的执行效率</strong> 。因为子程序切换不是线程切换，而是由程序自身控制，因此，没有线程切换的开销，和多线程比，线程数量越多，协程的性能优势就越明显。</p><p>第二大优势就是 <strong>不需要多线程的锁机制</strong> ，因为只有一个线程，也不存在同时写变量冲突，在协程中控制共享资源不加锁，只需要判断状态就好了，所以执行效率比多线程高很多。</p><h3 id="多进程，使用-Pool"><a href="#多进程，使用-Pool" class="headerlink" title="多进程，使用 Pool"></a>多进程，使用 Pool</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> multiprocessing <span class="keyword">import</span> Pool</span><br><span class="line"></span><br><span class="line">task_list = [</span><br><span class="line">    <span class="string">&#x27;https://www.jianshu.com/p/91b702f4f24a&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;https://www.jianshu.com/p/8e9e0b1b3a11&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;https://www.jianshu.com/p/7ef0f606c10b&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;https://www.jianshu.com/p/b117993f5008&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;https://www.jianshu.com/p/583d83f1ff81&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;https://www.jianshu.com/p/91b702f4f24a&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;https://www.jianshu.com/p/8e9e0b1b3a11&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;https://www.jianshu.com/p/7ef0f606c10b&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;https://www.jianshu.com/p/b117993f5008&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;https://www.jianshu.com/p/583d83f1ff81&#x27;</span></span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">header = &#123;</span><br><span class="line">        <span class="string">&#x27;Accept&#x27;</span>: <span class="string">&#x27;text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 &#x27;</span></span><br><span class="line">                      <span class="string">&#x27;(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">download</span>(<span class="params">url</span>):</span></span><br><span class="line">    response = requests.get(url,</span><br><span class="line">                            headers=header,</span><br><span class="line">                            timeout=<span class="number">30</span></span><br><span class="line">                            )</span><br><span class="line">    <span class="keyword">return</span> response.status_code</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">timeCul</span>(<span class="params">processNumberList</span>):</span></span><br><span class="line">    <span class="keyword">for</span> processNumber <span class="keyword">in</span> processNumberList:</span><br><span class="line">        p = Pool(processNumber)</span><br><span class="line">        time_old = time.time()</span><br><span class="line">        print(<span class="string">&#x27;res:&#x27;</span>,p.map(download, task_list))</span><br><span class="line">        time_new = time.time()</span><br><span class="line">        time_cost = time_new - time_old</span><br><span class="line">        print(<span class="string">&quot;Prcess number &#123;&#125;,Time cost &#123;&#125;&quot;</span>.format(processNumber,time_cost))</span><br><span class="line">        time.sleep(<span class="number">20</span>)</span><br><span class="line"></span><br><span class="line">timeCul([<span class="number">1</span>,<span class="number">3</span>,<span class="number">5</span>,<span class="number">7</span>,<span class="number">10</span>])</span><br></pre></td></tr></table></figure><pre><code>res: [200, 200, 200, 200, 200, 200, 200, 200, 200, 200]
Prcess number 1,Time cost 10.276863813400269
res: [200, 200, 200, 200, 200, 200, 200, 200, 200, 200]
Prcess number 3,Time cost 2.4015071392059326
res: [200, 200, 200, 200, 200, 200, 200, 200, 200, 200]
Prcess number 5,Time cost 2.639281988143921
res: [200, 200, 200, 200, 200, 200, 200, 200, 200, 200]
Prcess number 7,Time cost 1.357300043106079
res: [200, 200, 200, 200, 200, 200, 200, 200, 200, 200]
Prcess number 10,Time cost 0.7208449840545654</code></pre><p>可以看到,随着进程数量的提升,爬虫的效率得到了显著的提高</p><h3 id="多进程，使用-Process-对象"><a href="#多进程，使用-Process-对象" class="headerlink" title="多进程，使用 Process 对象"></a>多进程，使用 Process 对象</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> multiprocessing <span class="keyword">import</span> Process</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">f</span>(<span class="params">name</span>):</span></span><br><span class="line">    print(<span class="string">&#x27;hello&#x27;</span>, name)</span><br><span class="line"></span><br><span class="line">p_1 = Process(target=f, args=(<span class="string">&#x27;bob&#x27;</span>,))</span><br><span class="line">p_1.start()</span><br><span class="line">p_1.join()</span><br><span class="line"></span><br><span class="line">p_2 = Process(target=f, args=(<span class="string">&#x27;alice&#x27;</span>,))</span><br><span class="line">p_2.start()</span><br><span class="line">p_2.join()</span><br></pre></td></tr></table></figure><pre><code>hello bob
hello alice</code></pre><h3 id="关于多线程"><a href="#关于多线程" class="headerlink" title="关于多线程"></a>关于多线程</h3><p><strong>纯粹的多线程爬虫不适合复杂的任务</strong></p><p>当某一个线程的爬虫出现故障，由于内存共享机制，所有的线程会受到牵连</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> concurrent.futures <span class="keyword">import</span> ThreadPoolExecutor</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sayhello</span>(<span class="params">a</span>):</span></span><br><span class="line">    print(<span class="string">&quot;hello: &quot;</span>+a)</span><br><span class="line">    time.sleep(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    seed=[<span class="string">&quot;a&quot;</span>,<span class="string">&quot;b&quot;</span>,<span class="string">&quot;c&quot;</span>]</span><br><span class="line">    start1=time.time()</span><br><span class="line">    <span class="keyword">for</span> each <span class="keyword">in</span> seed:</span><br><span class="line">        sayhello(each)</span><br><span class="line">    end1=time.time()</span><br><span class="line">    print(<span class="string">&quot;time1: &quot;</span>+str(end1-start1))</span><br><span class="line">    start2=time.time()</span><br><span class="line">    <span class="keyword">with</span> ThreadPoolExecutor(<span class="number">3</span>) <span class="keyword">as</span> executor:</span><br><span class="line">        <span class="keyword">for</span> each <span class="keyword">in</span> seed:</span><br><span class="line">            executor.submit(sayhello,each)</span><br><span class="line">    end2=time.time()</span><br><span class="line">    print(<span class="string">&quot;time2: &quot;</span>+str(end2-start2))</span><br><span class="line">    start3=time.time()</span><br><span class="line">    <span class="keyword">with</span> ThreadPoolExecutor(<span class="number">3</span>) <span class="keyword">as</span> executor1:</span><br><span class="line">        executor1.map(sayhello,seed)</span><br><span class="line">    end3=time.time()</span><br><span class="line">    print(<span class="string">&quot;time3: &quot;</span>+str(end3-start3))</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure><h1 id="关于协程"><a href="#关于协程" class="headerlink" title="关于协程"></a>关于协程</h1><h2 id="协程的作用"><a href="#协程的作用" class="headerlink" title="协程的作用"></a>协程的作用</h2><p>简单总结一下协程的优缺点：</p><p>优点：</p><ol><li><p>无需线程上下文切换的开销（还是单线程）；</p></li><li><p>无需原子操作的锁定和同步的开销；</p></li><li><p>方便切换控制流，简化编程模型；</p></li><li><p>高并发+高扩展+低成本：一个 cpu 支持上万的协程都没有问题，适合用于高并发处理。</p></li></ol><p>缺点：</p><ol><li><p>无法利用多核的资源，协程本身是个单线程，它不能同时将单个 cpu 的多核用上，协程需要和进程配合才能运用到多 cpu 上（协程是跑在线程上的）；</p></li><li><p>进行阻塞操作时会阻塞掉整个程序：如 io；</p></li></ol><h2 id="示例演示"><a href="#示例演示" class="headerlink" title="示例演示"></a>示例演示</h2><p>协程是我这次复习的一个重头戏，所以给它一个完整的演示流程。这对于理解并发以及并发应该如何应用有着很大的意义。</p><p>首先，为了体现协程的高效率，我将传统的串行爬虫和协程爬虫进行一个效率对比。</p><h3 id="共同部分"><a href="#共同部分" class="headerlink" title="共同部分"></a>共同部分</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> asyncio</span><br><span class="line"><span class="keyword">import</span> aiohttp</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> ssl</span><br><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"><span class="keyword">from</span> asyncio.queues <span class="keyword">import</span> Queue</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> aiosocksy.connector <span class="keyword">import</span> ProxyConnector, ProxyClientRequest</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">links_list = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">18</span>):</span><br><span class="line">    url = <span class="string">&#x27;http://www.harumonia.top/index.php/page/&#123;&#125;/&#x27;</span>.format(i)</span><br><span class="line">    header = &#123;</span><br><span class="line">        <span class="string">&#x27;Accept&#x27;</span>: <span class="string">&#x27;text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 &#x27;</span></span><br><span class="line">                      <span class="string">&#x27;(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line">    response = requests.get(url,</span><br><span class="line">                            headers=header,</span><br><span class="line">                            timeout=<span class="number">5</span></span><br><span class="line">                            )</span><br><span class="line">    tree = etree.HTML(response.text)</span><br><span class="line">    article_links = tree.xpath(<span class="string">&#x27;//*[@id=&quot;post-panel&quot;]/div/div[@class=&quot;panel&quot;]/div[1]/a/@href&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> article_link <span class="keyword">in</span> article_links:</span><br><span class="line">        links_list.append(article_link)</span><br></pre></td></tr></table></figure><p>以上，获取 url 列表，是两只爬虫的共同部分，所以就摘出来，不加入计时。</p><h3 id="传统方法，顺序爬虫"><a href="#传统方法，顺序爬虫" class="headerlink" title="传统方法，顺序爬虫"></a>传统方法，顺序爬虫</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">%%timeit</span><br><span class="line">word_sum = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> link <span class="keyword">in</span> links_list:</span><br><span class="line">    res = requests.get(link,headers=header)</span><br><span class="line">    tree = etree.HTML(res.text)</span><br><span class="line">    word_num = re.match(<span class="string">&#x27;\d*&#x27;</span>, tree.xpath(<span class="string">&#x27;//*[@id=&quot;small_widgets&quot;]/ul/li[5]/span/text()&#x27;</span>)[<span class="number">0</span>]).group()</span><br><span class="line">    word_sum+=int(word_num)</span><br></pre></td></tr></table></figure><pre><code>47.9 s ± 6.06 s per loop (mean ± std. dev. of 7 runs, 1 loop each)</code></pre><h3 id="协程方法"><a href="#协程方法" class="headerlink" title="协程方法"></a>协程方法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br></pre></td><td class="code"><pre><span class="line">result_queue_1 = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">session_get</span>(<span class="params">session, url</span>):</span></span><br><span class="line">    headers = &#123;<span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/4.0 (compatible; MSIE 5.5; Windows NT)&#x27;</span>&#125;</span><br><span class="line">    timeout = aiohttp.ClientTimeout(total=<span class="number">20</span>)</span><br><span class="line">    response = <span class="keyword">await</span> session.get(</span><br><span class="line">        url,</span><br><span class="line">        timeout=timeout,</span><br><span class="line">        headers=headers,</span><br><span class="line">        ssl=ssl.SSLContext()</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">await</span> response.text(), response.status</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">download</span>(<span class="params">url</span>):</span></span><br><span class="line">    connector = ProxyConnector()</span><br><span class="line">    <span class="keyword">async</span> <span class="keyword">with</span> aiohttp.ClientSession(</span><br><span class="line">            connector=connector,</span><br><span class="line">            request_class=ProxyClientRequest</span><br><span class="line">    ) <span class="keyword">as</span> session:</span><br><span class="line">        ret, status = <span class="keyword">await</span> session_get(session, url)</span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27;window.location.href&#x27;</span> <span class="keyword">in</span> ret <span class="keyword">and</span> len(ret) &lt; <span class="number">1000</span>:</span><br><span class="line">            url = ret.split(<span class="string">&quot;window.location.href=&#x27;&quot;</span>)[<span class="number">1</span>].split(<span class="string">&quot;&#x27;&quot;</span>)[<span class="number">0</span>]</span><br><span class="line">            ret, status = <span class="keyword">await</span> session_get(session, url)</span><br><span class="line">        <span class="keyword">return</span> ret, status</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">parse_html</span>(<span class="params">content</span>):</span></span><br><span class="line">    tree = etree.HTML(content)</span><br><span class="line">    word_num = re.match(<span class="string">&#x27;\d*&#x27;</span>, tree.xpath(<span class="string">&#x27;//*[@id=&quot;small_widgets&quot;]/ul/li[5]/span/text()&#x27;</span>)[<span class="number">0</span>]).group()</span><br><span class="line">    <span class="keyword">return</span> int(word_num)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_all_article_links</span>():</span></span><br><span class="line">    links_list = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">18</span>):</span><br><span class="line">        url = <span class="string">&#x27;http://www.harumonia.top/index.php/page/&#123;&#125;/&#x27;</span>.format(i)</span><br><span class="line">        header = &#123;</span><br><span class="line">            <span class="string">&#x27;Accept&#x27;</span>: <span class="string">&#x27;text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8&#x27;</span>,</span><br><span class="line">            <span class="string">&#x27;User-Agent&#x27;</span>: <span class="string">&#x27;Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 &#x27;</span></span><br><span class="line">                          <span class="string">&#x27;(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36&#x27;</span></span><br><span class="line">        &#125;</span><br><span class="line">        response = requests.get(url,</span><br><span class="line">                                headers=header,</span><br><span class="line">                                timeout=<span class="number">5</span></span><br><span class="line">                                )</span><br><span class="line">        tree = etree.HTML(response.text)</span><br><span class="line">        article_links = tree.xpath(<span class="string">&#x27;//*[@id=&quot;post-panel&quot;]/div/div[@class=&quot;panel&quot;]/div[1]/a/@href&#x27;</span>)</span><br><span class="line">        <span class="keyword">for</span> article_link <span class="keyword">in</span> article_links:</span><br><span class="line">            links_list.append(article_link)</span><br><span class="line">            print(article_link)</span><br><span class="line">    <span class="keyword">return</span> links_list</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">down_and_parse_task</span>(<span class="params">url</span>):</span></span><br><span class="line">    error = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">for</span> retry_cnt <span class="keyword">in</span> range(<span class="number">3</span>):</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            html, status = <span class="keyword">await</span> download(url)</span><br><span class="line">            <span class="keyword">if</span> status != <span class="number">200</span>:</span><br><span class="line">                print(<span class="string">&#x27;false&#x27;</span>)</span><br><span class="line">                html, status = <span class="keyword">await</span> download(url)</span><br><span class="line">            word_num = <span class="keyword">await</span> parse_html(html)</span><br><span class="line">            print(<span class="string">&#x27;word num:&#x27;</span>, word_num)</span><br><span class="line">            <span class="keyword">return</span> word_num</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            error = e</span><br><span class="line">            print(retry_cnt, e)</span><br><span class="line">            <span class="keyword">await</span> asyncio.sleep(<span class="number">1</span>)</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">raise</span> error</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">async</span> <span class="function"><span class="keyword">def</span> <span class="title">main</span>(<span class="params">all_links</span>):</span></span><br><span class="line">    task_queue = Queue()</span><br><span class="line">    task = []</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> set(all_links):</span><br><span class="line">        <span class="keyword">await</span> task_queue.put(item)</span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">not</span> task_queue.empty():</span><br><span class="line">        url = task_queue.get_nowait()</span><br><span class="line">        print(<span class="string">&#x27;now start&#x27;</span>, url)</span><br><span class="line">        task.append(asyncio.ensure_future(down_and_parse_task(url)))</span><br><span class="line">    tasks = <span class="keyword">await</span> asyncio.gather(*task)</span><br><span class="line">    <span class="keyword">for</span> foo <span class="keyword">in</span> tasks:</span><br><span class="line">        result_queue_1.append(foo)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">loop = asyncio.get_event_loop()</span><br><span class="line">loop.run_until_complete(main())</span><br></pre></td></tr></table></figure><blockquote><p>time cost 16.03649091720581 s<br>字数 = 291738</p></blockquote><p>ps.由于 jupyter 自身的限制，所以这里使用 pycharm 运行并计时</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>可以看出，协程方法下，代码的运行效率大约是传统串行方式的 3 倍，并且，随着运行量级的增加，效率将会呈指数级提升。</p><p>由进程到线程，由线程到协程，任务的划分越来越精细，但是代价是什么呢？</p><br><p><strong>补充说明</strong> ：</p><ol><li>无论是串行还是协程，都会面临爬取频率过高而触发反爬虫机制的问题。这在高效率的协程状况下尤为明显，这里就要使用代理来规避这一问题。</li><li>两者的代码量存在很大的差异，这里主要是因为在写协程的时候进行了代码规范，只是看上去代码量多了很多而已。（当然，协程的代码量必然是比传统方法多的）</li><li>爬虫不要玩的太狠，曾经有人将爬虫挂在服务器上日夜爬取某网站，被判定为攻击，最终被反制(病毒攻击)的先例。同时，也要兼顾一些法律方面的问题。</li></ol><h2 id="后记"><a href="#后记" class="headerlink" title="后记"></a>后记</h2><ol><li>暂时就先整理一下并发相关的知识吧.最近事务实在有点多了.</li><li>在完成这一篇的同时,收到了导师”将网站项目进行多进程改造”的要求,好吧…本来想偷个懒只研究协程的,最终还是一个都跑不掉 o(╥﹏╥)o</li><li>鲨雕终于要回来辽<del>~</del></li></ol></div><div><ul class="post-copyright"><li class="post-copyright-author"><strong>本文作者： </strong>harumonia</li><li class="post-copyright-link"><strong>本文链接：</strong> <a href="https://blog.harumonia.moe/2020-01-08-spider-review-2-Improve-efficiency/" title="python爬虫复习(2) 提高效率">https://blog.harumonia.moe/2020-01-08-spider-review-2-Improve-efficiency/</a></li><li class="post-copyright-license"><strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/CC%20BY-NC-SA%204.0/4.0/" rel="noopener" target="_blank"><i class="fa fa-fw fa-creative-commons"></i>CC BY-NC-SA 4.0</a> 许可协议。转载请注明出处！</li></ul></div><footer class="post-footer"><div class="post-tags"><a href="/tags/spider/" rel="tag"><i class="fa fa-tag"></i> spider</a> <a href="/tags/%E5%8D%8F%E7%A8%8B/" rel="tag"><i class="fa fa-tag"></i> 协程</a></div><div class="post-nav"><div class="post-nav-item"><a href="/2020-01-05-spider-review-1-selenium/" rel="prev" title="python爬虫复习(1) selenium"><i class="fa fa-chevron-left"></i> python爬虫复习(1) selenium</a></div><div class="post-nav-item"><a href="/2020-01-13-spider-review-3-splash/" rel="next" title="python爬虫复习(3) splash && 数据分析小试">python爬虫复习(3) splash && 数据分析小试 <i class="fa fa-chevron-right"></i></a></div></div></footer></article></div><div class="comments" id="valine-comments"></div><script>window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }</script></div><div class="toggle sidebar-toggle"><span class="toggle-line toggle-line-first"></span> <span class="toggle-line toggle-line-middle"></span> <span class="toggle-line toggle-line-last"></span></div><aside class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc">文章目录</li><li class="sidebar-nav-overview">站点概览</li></ul><div class="post-toc-wrap sidebar-panel"><div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%B9%B6%E5%8F%91"><span class="nav-number">1.</span> <span class="nav-text">并发</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%89%8D%E8%A8%80"><span class="nav-number">1.1.</span> <span class="nav-text">前言</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#python-%E4%B8%AD%E7%9A%84%E5%A4%9A%E8%BF%9B%E7%A8%8B%E6%96%B9%E6%B3%95"><span class="nav-number">1.2.</span> <span class="nav-text">python 中的多进程方法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A4%9A%E7%BA%BF%E7%A8%8B%E3%80%81%E5%A4%9A%E8%BF%9B%E7%A8%8B%E3%80%81%E5%8D%8F%E7%A8%8B%E7%88%AC%E8%99%AB"><span class="nav-number">1.2.1.</span> <span class="nav-text">多线程、多进程、协程爬虫</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%BF%9B%E7%A8%8B%E3%80%81%E7%BA%BF%E7%A8%8B%E3%80%81%E5%8D%8F%E7%A8%8B%E7%9A%84%E5%8C%BA%E5%88%AB"><span class="nav-number">1.2.2.</span> <span class="nav-text">进程、线程、协程的区别</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%8D%8F%E7%A8%8B%E7%9A%84%E4%BC%98%E5%8A%BF%EF%BC%9A"><span class="nav-number">1.2.2.1.</span> <span class="nav-text">协程的优势：</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A4%9A%E8%BF%9B%E7%A8%8B%EF%BC%8C%E4%BD%BF%E7%94%A8-Pool"><span class="nav-number">1.2.3.</span> <span class="nav-text">多进程，使用 Pool</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A4%9A%E8%BF%9B%E7%A8%8B%EF%BC%8C%E4%BD%BF%E7%94%A8-Process-%E5%AF%B9%E8%B1%A1"><span class="nav-number">1.2.4.</span> <span class="nav-text">多进程，使用 Process 对象</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%85%B3%E4%BA%8E%E5%A4%9A%E7%BA%BF%E7%A8%8B"><span class="nav-number">1.2.5.</span> <span class="nav-text">关于多线程</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%85%B3%E4%BA%8E%E5%8D%8F%E7%A8%8B"><span class="nav-number">2.</span> <span class="nav-text">关于协程</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8D%8F%E7%A8%8B%E7%9A%84%E4%BD%9C%E7%94%A8"><span class="nav-number">2.1.</span> <span class="nav-text">协程的作用</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%A4%BA%E4%BE%8B%E6%BC%94%E7%A4%BA"><span class="nav-number">2.2.</span> <span class="nav-text">示例演示</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%85%B1%E5%90%8C%E9%83%A8%E5%88%86"><span class="nav-number">2.2.1.</span> <span class="nav-text">共同部分</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BC%A0%E7%BB%9F%E6%96%B9%E6%B3%95%EF%BC%8C%E9%A1%BA%E5%BA%8F%E7%88%AC%E8%99%AB"><span class="nav-number">2.2.2.</span> <span class="nav-text">传统方法，顺序爬虫</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8D%8F%E7%A8%8B%E6%96%B9%E6%B3%95"><span class="nav-number">2.2.3.</span> <span class="nav-text">协程方法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E6%80%BB%E7%BB%93"><span class="nav-number">2.2.4.</span> <span class="nav-text">总结</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%90%8E%E8%AE%B0"><span class="nav-number">2.3.</span> <span class="nav-text">后记</span></a></li></ol></li></ol></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" alt="harumonia" src="https://harumona-blog.oss-cn-beijing.aliyuncs.com/blog/Ocabe.webp"><p class="site-author-name" itemprop="name">harumonia</p><div class="site-description" itemprop="description">lazy</div></div><div class="site-state-wrap motion-element"><nav class="site-state"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">106</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"><a href="/categories/"><span class="site-state-item-count">18</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"><a href="/tags/"><span class="site-state-item-count">56</span> <span class="site-state-item-name">标签</span></a></div></nav></div><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/zxjlm" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;zxjlm" rel="noopener" target="_blank"><i class="fa fa-fw fa-fab fa-github"></i>GitHub</a> </span><span class="links-of-author-item"><a href="mailto:zxjlm233@gmail.com" title="E-Mail → mailto:zxjlm233@gmail.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-fab fa-envelope"></i>E-Mail</a></span></div></div><div class="back-to-top motion-element"><i class="fa fa-arrow-up"></i> <span>0%</span></div></div></aside><div id="sidebar-dimmer"></div></div></main><footer class="footer"><div class="footer-inner"><div class="copyright">&copy; 2017 – <span itemprop="copyrightYear">2020</span> <span class="with-love"><i class="fa fa-fab fa-asterisk"></i> </span><span class="author" itemprop="copyrightHolder">harumonia</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-area-chart"></i> </span><span class="post-meta-item-text">站点总字数：</span> <span title="站点总字数">366k</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-coffee"></i> </span><span class="post-meta-item-text">站点阅读时长 &asymp;</span> <span title="站点阅读时长">19:05</span></div></div></footer></div><script src="/lib/anime.min.js"></script><script src="//cdn.jsdelivr.net/npm/medium-zoom@1/dist/medium-zoom.min.js"></script><script src="//cdn.jsdelivr.net/npm/lozad@1/dist/lozad.min.js"></script><script src="/lib/velocity/velocity.min.js"></script><script src="/lib/velocity/velocity.ui.min.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/pisces.js"></script><script src="/js/next-boot.js"></script><script src="/js/local-search.js"></script><script>NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//cdnjs.cloudflare.com/ajax/libs/valine/1.3.10/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : true,
      appId      : 'MRbMQ94D5q51YRYIbsRF0kcH-gzGzoHsz',
      appKey     : 'A9JJBbjhfc9liCzCJgWIxpDa',
      placeholder: "Just go go",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : true,
      lang       : 'zh-cn' || 'zh-cn',
      path       : location.pathname,
      recordIP   : true,
      serverURLs : ''
    });
  }, window.Valine);
});</script><script async src="/js/cursor/fireworks.js"></script></body></html>